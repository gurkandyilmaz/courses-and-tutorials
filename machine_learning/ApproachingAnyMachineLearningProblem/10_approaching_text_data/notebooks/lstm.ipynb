{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:29.823291Z",
     "iopub.status.busy": "2021-06-25T19:05:29.822937Z",
     "iopub.status.idle": "2021-06-25T19:05:29.845490Z",
     "shell.execute_reply": "2021-06-25T19:05:29.844389Z",
     "shell.execute_reply.started": "2021-06-25T19:05:29.823258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fasttext-wikinews/wiki-news-300d-1M.vec\n",
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:23:07.345822Z",
     "iopub.status.busy": "2021-06-25T19:23:07.345445Z",
     "iopub.status.idle": "2021-06-25T19:23:07.350717Z",
     "shell.execute_reply": "2021-06-25T19:23:07.349464Z",
     "shell.execute_reply.started": "2021-06-25T19:23:07.345792Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:29.859846Z",
     "iopub.status.busy": "2021-06-25T19:05:29.859212Z",
     "iopub.status.idle": "2021-06-25T19:05:29.871556Z",
     "shell.execute_reply": "2021-06-25T19:05:29.870560Z",
     "shell.execute_reply.started": "2021-06-25T19:05:29.859799Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA = \"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\n",
    "FASTTEXT_EMBEDDINGS = \"../input/fasttext-wikinews/wiki-news-300d-1M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:29.873691Z",
     "iopub.status.busy": "2021-06-25T19:05:29.873268Z",
     "iopub.status.idle": "2021-06-25T19:05:29.884971Z",
     "shell.execute_reply": "2021-06-25T19:05:29.884161Z",
     "shell.execute_reply.started": "2021-06-25T19:05:29.873647Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_to_vec(sentence, embedding_dict={}, stop_words=[], tokenizer=None):\n",
    "    words = str(sentence).lower()\n",
    "    words = tokenizer(words)\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    M = []\n",
    "    for w in words:\n",
    "        if w in embedding_dict:\n",
    "            M.append(embedding_dict[w])\n",
    "    \n",
    "    if len(M) == 0:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "    v = np.array(M).sum(axis=0)\n",
    "    \n",
    "    return v / np.sqrt((v**2).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:29.887149Z",
     "iopub.status.busy": "2021-06-25T19:05:29.886704Z",
     "iopub.status.idle": "2021-06-25T19:05:29.905891Z",
     "shell.execute_reply": "2021-06-25T19:05:29.904885Z",
     "shell.execute_reply.started": "2021-06-25T19:05:29.887104Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def load_vectors(fname):\n",
    "    # taken from: https://fasttext.cc/docs/en/english-vectors.html\n",
    "    fin = io.open(fname,'r',encoding='utf-8',newline='\\n',errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:30.868121Z",
     "iopub.status.busy": "2021-06-25T19:05:30.867748Z",
     "iopub.status.idle": "2021-06-25T19:05:31.373754Z",
     "shell.execute_reply": "2021-06-25T19:05:31.372693Z",
     "shell.execute_reply.started": "2021-06-25T19:05:30.868082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 29.3 ms, total: 178 ms\n",
      "Wall time: 496 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(DATA, nrows=10000)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(lambda label: 1 if label==\"positive\" else 0)\n",
    "df = df.sample(frac=1.0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:05:42.140405Z",
     "iopub.status.busy": "2021-06-25T19:05:42.140014Z",
     "iopub.status.idle": "2021-06-25T19:07:35.186515Z",
     "shell.execute_reply": "2021-06-25T19:07:35.185562Z",
     "shell.execute_reply.started": "2021-06-25T19:05:42.140374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Embeddings...\")\n",
    "embeddings = load_vectors(FASTTEXT_EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:17:36.973365Z",
     "iopub.status.busy": "2021-06-25T19:17:36.972958Z",
     "iopub.status.idle": "2021-06-25T19:17:36.983126Z",
     "shell.execute_reply": "2021-06-25T19:17:36.980511Z",
     "shell.execute_reply.started": "2021-06-25T19:17:36.973331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8331158890694513\n",
      "0.7301328920606268\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "good = np.array(embeddings.get(\"good\"))\n",
    "bad = np.array(embeddings.get(\"bad\"))\n",
    "worst = np.array(embeddings.get(\"worst\"))\n",
    "best = np.array(embeddings.get(\"best\"))\n",
    "\n",
    "good_bad = dot(good, bad) / (norm(good)*norm(bad))\n",
    "print(good_bad)\n",
    "best_worst = dot(best, worst) / (norm(best)*norm(worst))\n",
    "print(best_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:17:47.353007Z",
     "iopub.status.busy": "2021-06-25T19:17:47.352470Z",
     "iopub.status.idle": "2021-06-25T19:19:51.731971Z",
     "shell.execute_reply": "2021-06-25T19:19:51.730633Z",
     "shell.execute_reply.started": "2021-06-25T19:17:47.352972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Vectors..\n",
      "FOLD:  0\n",
      "Accuracy: 0.798\n",
      "FOLD:  1\n",
      "Accuracy: 0.824\n",
      "FOLD:  2\n",
      "Accuracy: 0.817\n",
      "CPU times: user 2min 4s, sys: 832 ms, total: 2min 5s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Sentence Vectors..\")\n",
    "vectors = []\n",
    "for review in df[\"review\"].values:\n",
    "    vectors.append(\n",
    "        sentence_to_vec(\n",
    "            sentence = review,\n",
    "            embedding_dict = embeddings,\n",
    "            stop_words = [],\n",
    "            tokenizer = word_tokenize\n",
    "        )\n",
    "    )\n",
    "    \n",
    "vectors = np.array(vectors)\n",
    "y = df[\"sentiment\"].values\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=3)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X=vectors, y=y)):\n",
    "    print(\"FOLD: \", fold)\n",
    "    xtrain = vectors[train_idx, :]\n",
    "    xval = vectors[val_idx, :]\n",
    "    ytrain = y[train_idx]\n",
    "    yval = y[val_idx]\n",
    "    \n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds = model.predict(xval)\n",
    "    acc = metrics.accuracy_score(yval, preds)\n",
    "    print(f\"Accuracy: {np.round(acc, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:27:20.611245Z",
     "iopub.status.busy": "2021-06-25T19:27:20.610877Z",
     "iopub.status.idle": "2021-06-25T19:27:20.636782Z",
     "shell.execute_reply": "2021-06-25T19:27:20.635591Z",
     "shell.execute_reply.started": "2021-06-25T19:27:20.611215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.51 ms, sys: 31 µs, total: 9.54 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sure it may not be a classic but it's one full...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This might have been an excellent flick. Howev...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This poor remake of the 1963 classic starts re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At school I was taught how some shots were cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farrah Fawcett gives an award nominated perfor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>I mistakenly kept myself awake late last night...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Please! Do not waste any money on this movie. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>I wanted to see the movie because of an articl...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>If this movie is coming to a theater near you,...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>The Internet Database lists this as a TV show....</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  folds\n",
       "0     Sure it may not be a classic but it's one full...          1      0\n",
       "1     This might have been an excellent flick. Howev...          0      0\n",
       "2     This poor remake of the 1963 classic starts re...          0      0\n",
       "3     At school I was taught how some shots were cal...          1      0\n",
       "4     Farrah Fawcett gives an award nominated perfor...          1      0\n",
       "...                                                 ...        ...    ...\n",
       "9995  I mistakenly kept myself awake late last night...          0      4\n",
       "9996  Please! Do not waste any money on this movie. ...          0      4\n",
       "9997  I wanted to see the movie because of an articl...          0      4\n",
       "9998  If this movie is coming to a theater near you,...          0      4\n",
       "9999  The Internet Database lists this as a TV show....          1      4\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#create_folds.py\n",
    "def create_folds(df, num_folds=5):\n",
    "    df = df.sample(frac=1.0).reset_index(drop=True)\n",
    "    df[\"folds\"] = -1\n",
    "    kf = model_selection.StratifiedKFold(n_splits=num_folds)\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X=df[\"review\"], y=df[\"sentiment\"])):\n",
    "        df.loc[val_idx, \"folds\"] = fold\n",
    "\n",
    "    return df\n",
    "\n",
    "df = create_folds(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:30:58.924328Z",
     "iopub.status.busy": "2021-06-25T19:30:58.923896Z",
     "iopub.status.idle": "2021-06-25T19:30:58.930852Z",
     "shell.execute_reply": "2021-06-25T19:30:58.930014Z",
     "shell.execute_reply.started": "2021-06-25T19:30:58.924297Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset.py\n",
    "import torch\n",
    "\n",
    "class IMDBDataset:\n",
    "    def __init__(self, reviews, targets):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        review = self.reviews[item, :]\n",
    "        target = self.targets[item]\n",
    "        return {\n",
    "            \"review\": torch.tensor(review, dtype=torch.long),\n",
    "            \"target\": torch.tensor(review, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lstm.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix):\n",
    "        super().__init__()\n",
    "        num_words = embedding_matrix.shape[0]\n",
    "        embedding_dim = embedding_matrix.shape[1]\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=embedding_dim)\n",
    "        \n",
    "        self.embedding.weight = nn.Parameter(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "        )\n",
    "        \n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            128,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(512,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        avg_pool = torch.mean(x, 1)\n",
    "        max_pool = torch.max(x, 1)\n",
    "        \n",
    "        out = torch.cat((avg_pool, max_pool), 1)\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-25T19:44:36.774229Z",
     "iopub.status.busy": "2021-06-25T19:44:36.773808Z",
     "iopub.status.idle": "2021-06-25T19:44:36.784733Z",
     "shell.execute_reply": "2021-06-25T19:44:36.783719Z",
     "shell.execute_reply.started": "2021-06-25T19:44:36.774184Z"
    }
   },
   "outputs": [],
   "source": [
    "#engine.py\n",
    "\n",
    "def train(data_loader, model, optimizer, device):\n",
    "    for data in data_loader:\n",
    "        reviews = data[\"review\"]\n",
    "        targets = data[\"target\"]\n",
    "        \n",
    "        reviews = reviews.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(reviews)\n",
    "        \n",
    "        loss = nn.BCEWithLogitsLoss(predictions, targets.view(-1,1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def evaluate(data_loader, model, device):\n",
    "    final_preds = []\n",
    "    final_targets = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            reviews = data[\"review\"]\n",
    "            targets = data[\"target\"]\n",
    "            reviews = reviews.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "            \n",
    "            preds = model(reviews)\n",
    "            \n",
    "            preds = preds.cpu().numpy().tolist()\n",
    "            targets = data[\"target\"].cpu().numpy().tolist()\n",
    "            final_preds.extend(preds)\n",
    "            final_targets.extend(targets)\n",
    "            \n",
    "    return final_preds, final_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
