{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e9fde7-7a5f-47be-b447-3d0e8f83877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2328ecdd-b0b6-44dc-be29-5ddcf26a8a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.406443</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>0.702296</td>\n",
       "      <td>1.637062</td>\n",
       "      <td>0.613154</td>\n",
       "      <td>0.055370</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>1.507169</td>\n",
       "      <td>116.103673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057764</td>\n",
       "      <td>-0.055698</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>-0.398106</td>\n",
       "      <td>-0.393953</td>\n",
       "      <td>0.106571</td>\n",
       "      <td>1.763514</td>\n",
       "      <td>-0.371550</td>\n",
       "      <td>-0.984233</td>\n",
       "      <td>-0.315364</td>\n",
       "      <td>-79.898140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095807</td>\n",
       "      <td>0.425077</td>\n",
       "      <td>1.347864</td>\n",
       "      <td>-1.767760</td>\n",
       "      <td>0.516914</td>\n",
       "      <td>0.692119</td>\n",
       "      <td>-0.867617</td>\n",
       "      <td>-0.961747</td>\n",
       "      <td>1.899550</td>\n",
       "      <td>-0.790154</td>\n",
       "      <td>10.834235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.075314</td>\n",
       "      <td>-0.369439</td>\n",
       "      <td>-0.294164</td>\n",
       "      <td>-0.551424</td>\n",
       "      <td>-0.167901</td>\n",
       "      <td>-1.608192</td>\n",
       "      <td>0.457403</td>\n",
       "      <td>1.054794</td>\n",
       "      <td>-0.692943</td>\n",
       "      <td>0.614384</td>\n",
       "      <td>-192.035952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.807445</td>\n",
       "      <td>1.564458</td>\n",
       "      <td>0.962063</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>1.092314</td>\n",
       "      <td>-0.589738</td>\n",
       "      <td>0.578448</td>\n",
       "      <td>1.100733</td>\n",
       "      <td>0.265488</td>\n",
       "      <td>-0.921710</td>\n",
       "      <td>79.689091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.116028</td>\n",
       "      <td>0.914617</td>\n",
       "      <td>-0.535280</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>-1.739501</td>\n",
       "      <td>-1.267179</td>\n",
       "      <td>-2.727517</td>\n",
       "      <td>0.324345</td>\n",
       "      <td>0.172801</td>\n",
       "      <td>-0.627018</td>\n",
       "      <td>-169.377685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.953975</td>\n",
       "      <td>-1.753854</td>\n",
       "      <td>-1.021328</td>\n",
       "      <td>0.659155</td>\n",
       "      <td>-2.555383</td>\n",
       "      <td>-0.748612</td>\n",
       "      <td>0.270809</td>\n",
       "      <td>0.150141</td>\n",
       "      <td>-0.221071</td>\n",
       "      <td>-0.079708</td>\n",
       "      <td>-210.255794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.583881</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>1.128371</td>\n",
       "      <td>1.431660</td>\n",
       "      <td>-0.699556</td>\n",
       "      <td>-1.341429</td>\n",
       "      <td>0.791885</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>1.025854</td>\n",
       "      <td>-0.537191</td>\n",
       "      <td>52.593579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.085207</td>\n",
       "      <td>1.830395</td>\n",
       "      <td>0.811040</td>\n",
       "      <td>-0.636988</td>\n",
       "      <td>0.432056</td>\n",
       "      <td>1.070411</td>\n",
       "      <td>-1.274225</td>\n",
       "      <td>-0.114573</td>\n",
       "      <td>-0.575302</td>\n",
       "      <td>0.138895</td>\n",
       "      <td>35.421726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.082631</td>\n",
       "      <td>0.408684</td>\n",
       "      <td>0.041609</td>\n",
       "      <td>0.431081</td>\n",
       "      <td>0.921789</td>\n",
       "      <td>0.708994</td>\n",
       "      <td>-0.640788</td>\n",
       "      <td>0.597326</td>\n",
       "      <td>-1.038590</td>\n",
       "      <td>1.489848</td>\n",
       "      <td>121.546467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
       "0  -1.406443  0.095395  0.702296  1.637062  0.613154  0.055370 -0.240875   \n",
       "1   0.057764 -0.055698  0.096949 -0.398106 -0.393953  0.106571  1.763514   \n",
       "2  -0.095807  0.425077  1.347864 -1.767760  0.516914  0.692119 -0.867617   \n",
       "3  -1.075314 -0.369439 -0.294164 -0.551424 -0.167901 -1.608192  0.457403   \n",
       "4  -0.807445  1.564458  0.962063  0.066150  1.092314 -0.589738  0.578448   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.116028  0.914617 -0.535280  0.004435 -1.739501 -1.267179 -2.727517   \n",
       "96 -0.953975 -1.753854 -1.021328  0.659155 -2.555383 -0.748612  0.270809   \n",
       "97 -0.583881 -0.006963  1.128371  1.431660 -0.699556 -1.341429  0.791885   \n",
       "98 -0.085207  1.830395  0.811040 -0.636988  0.432056  1.070411 -1.274225   \n",
       "99  0.082631  0.408684  0.041609  0.431081  0.921789  0.708994 -0.640788   \n",
       "\n",
       "         x_7       x_8       x_9      target  \n",
       "0   0.120853  0.190918  1.507169  116.103673  \n",
       "1  -0.371550 -0.984233 -0.315364  -79.898140  \n",
       "2  -0.961747  1.899550 -0.790154   10.834235  \n",
       "3   1.054794 -0.692943  0.614384 -192.035952  \n",
       "4   1.100733  0.265488 -0.921710   79.689091  \n",
       "..       ...       ...       ...         ...  \n",
       "95  0.324345  0.172801 -0.627018 -169.377685  \n",
       "96  0.150141 -0.221071 -0.079708 -210.255794  \n",
       "97 -0.103101  1.025854 -0.537191   52.593579  \n",
       "98 -0.114573 -0.575302  0.138895   35.421726  \n",
       "99  0.597326 -1.038590  1.489848  121.546467  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_random_data(n_rows, n_columns, problem_type):\n",
    "    if problem_type == \"classification\":\n",
    "        x, y = make_classification(n_samples=n_rows, n_features=n_columns, n_classes=2, random_state=21)\n",
    "    elif problem_type == \"regression\":\n",
    "        x, y = make_regression(n_samples=n_rows, n_features=n_columns)\n",
    "    \n",
    "    feature_names = [f\"x_{i}\" for i in range(x.shape[1])]\n",
    "    feature_names.append(\"target\")\n",
    "    \n",
    "    return pd.DataFrame(np.concatenate((x, y.reshape(-1,1)), axis=1), columns=feature_names)\n",
    "\n",
    "data_classification = make_random_data(n_rows=100, n_columns=10, problem_type=\"classification\")\n",
    "data_regression = make_random_data(n_rows=100, n_columns=10, problem_type=\"regression\")\n",
    "data_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cdb6de2-dca3-41bc-a978-c21092733ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_0       1.317052\n",
       "x_1       1.433999\n",
       "x_2       0.813250\n",
       "x_3       1.137152\n",
       "x_4       0.870081\n",
       "x_5       0.774427\n",
       "x_6       0.870288\n",
       "x_7       1.048479\n",
       "x_8       1.397943\n",
       "x_9       2.372108\n",
       "target    0.252525\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fe72752-8f6e-4ab8-9b99-bd4644d63a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.304180</td>\n",
       "      <td>0.499770</td>\n",
       "      <td>-0.930986</td>\n",
       "      <td>-0.498250</td>\n",
       "      <td>0.740040</td>\n",
       "      <td>1.103170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159726</td>\n",
       "      <td>1.360251</td>\n",
       "      <td>-1.573324</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.171186</td>\n",
       "      <td>1.893630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.984758</td>\n",
       "      <td>0.987433</td>\n",
       "      <td>1.422739</td>\n",
       "      <td>-1.800050</td>\n",
       "      <td>-1.055891</td>\n",
       "      <td>0.664531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189401</td>\n",
       "      <td>0.264090</td>\n",
       "      <td>1.347407</td>\n",
       "      <td>-0.631017</td>\n",
       "      <td>0.227037</td>\n",
       "      <td>0.484254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074976</td>\n",
       "      <td>-1.781137</td>\n",
       "      <td>-2.286583</td>\n",
       "      <td>-0.518173</td>\n",
       "      <td>1.230037</td>\n",
       "      <td>-1.604579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.449590</td>\n",
       "      <td>0.373126</td>\n",
       "      <td>-0.669493</td>\n",
       "      <td>0.428601</td>\n",
       "      <td>-1.237158</td>\n",
       "      <td>-0.253206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.832561</td>\n",
       "      <td>-0.855009</td>\n",
       "      <td>-0.076494</td>\n",
       "      <td>1.012445</td>\n",
       "      <td>-0.537829</td>\n",
       "      <td>-1.449137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.027553</td>\n",
       "      <td>1.100880</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.260149</td>\n",
       "      <td>-0.829631</td>\n",
       "      <td>0.950012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.471626</td>\n",
       "      <td>-1.777680</td>\n",
       "      <td>0.650902</td>\n",
       "      <td>-0.694024</td>\n",
       "      <td>0.163840</td>\n",
       "      <td>-2.241550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-2.475892</td>\n",
       "      <td>-1.542218</td>\n",
       "      <td>-0.831998</td>\n",
       "      <td>-0.016413</td>\n",
       "      <td>-0.200021</td>\n",
       "      <td>-2.150520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "0  -0.304180  0.499770 -0.930986 -0.498250  0.740040  1.103170\n",
       "1   0.159726  1.360251 -1.573324  0.236686  0.171186  1.893630\n",
       "2   1.984758  0.987433  1.422739 -1.800050 -1.055891  0.664531\n",
       "3   0.189401  0.264090  1.347407 -0.631017  0.227037  0.484254\n",
       "4   0.074976 -1.781137 -2.286583 -0.518173  1.230037 -1.604579\n",
       "..       ...       ...       ...       ...       ...       ...\n",
       "95 -0.449590  0.373126 -0.669493  0.428601 -1.237158 -0.253206\n",
       "96  0.832561 -0.855009 -0.076494  1.012445 -0.537829 -1.449137\n",
       "97 -1.027553  1.100880  0.842681  0.260149 -0.829631  0.950012\n",
       "98  0.471626 -1.777680  0.650902 -0.694024  0.163840 -2.241550\n",
       "99 -2.475892 -1.542218 -0.831998 -0.016413 -0.200021 -2.150520\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features that have low variance ie. they are almost constant\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thres = VarianceThreshold(threshold=1.0)\n",
    "transformed_data = var_thres.fit_transform(data_classification.drop(columns=[\"target\"]))\n",
    "pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cd39597-cddf-4ef5-8492-906f1ee6e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157444</td>\n",
       "      <td>0.111285</td>\n",
       "      <td>-0.087054</td>\n",
       "      <td>0.087253</td>\n",
       "      <td>-0.017382</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>-0.036804</td>\n",
       "      <td>0.144146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>0.157444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>0.072759</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.234263</td>\n",
       "      <td>0.085414</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>-0.275968</td>\n",
       "      <td>0.896043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_2</th>\n",
       "      <td>0.111285</td>\n",
       "      <td>0.674399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>-0.120620</td>\n",
       "      <td>0.180651</td>\n",
       "      <td>0.062325</td>\n",
       "      <td>0.145982</td>\n",
       "      <td>0.523582</td>\n",
       "      <td>0.932101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_3</th>\n",
       "      <td>-0.087054</td>\n",
       "      <td>0.072759</td>\n",
       "      <td>-0.018128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.086677</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>-0.076379</td>\n",
       "      <td>0.089306</td>\n",
       "      <td>-0.107552</td>\n",
       "      <td>0.024791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>0.087253</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>-0.120620</td>\n",
       "      <td>-0.086677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>-0.012482</td>\n",
       "      <td>-0.159761</td>\n",
       "      <td>-0.071360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_5</th>\n",
       "      <td>-0.017382</td>\n",
       "      <td>0.234263</td>\n",
       "      <td>0.180651</td>\n",
       "      <td>-0.005972</td>\n",
       "      <td>-0.097443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>0.240766</td>\n",
       "      <td>-0.035146</td>\n",
       "      <td>0.223538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_6</th>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.085414</td>\n",
       "      <td>0.062325</td>\n",
       "      <td>-0.076379</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>-0.007593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>-0.017424</td>\n",
       "      <td>0.079374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_7</th>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.170274</td>\n",
       "      <td>0.145982</td>\n",
       "      <td>0.089306</td>\n",
       "      <td>-0.012482</td>\n",
       "      <td>0.240766</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>0.171303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_8</th>\n",
       "      <td>-0.036804</td>\n",
       "      <td>-0.275968</td>\n",
       "      <td>0.523582</td>\n",
       "      <td>-0.107552</td>\n",
       "      <td>-0.159761</td>\n",
       "      <td>-0.035146</td>\n",
       "      <td>-0.017424</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_9</th>\n",
       "      <td>0.144146</td>\n",
       "      <td>0.896043</td>\n",
       "      <td>0.932101</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>-0.071360</td>\n",
       "      <td>0.223538</td>\n",
       "      <td>0.079374</td>\n",
       "      <td>0.171303</td>\n",
       "      <td>0.179447</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
       "x_0  1.000000  0.157444  0.111285 -0.087054  0.087253 -0.017382  0.011572   \n",
       "x_1  0.157444  1.000000  0.674399  0.072759  0.002379  0.234263  0.085414   \n",
       "x_2  0.111285  0.674399  1.000000 -0.018128 -0.120620  0.180651  0.062325   \n",
       "x_3 -0.087054  0.072759 -0.018128  1.000000 -0.086677 -0.005972 -0.076379   \n",
       "x_4  0.087253  0.002379 -0.120620 -0.086677  1.000000 -0.097443  0.015572   \n",
       "x_5 -0.017382  0.234263  0.180651 -0.005972 -0.097443  1.000000 -0.007593   \n",
       "x_6  0.011572  0.085414  0.062325 -0.076379  0.015572 -0.007593  1.000000   \n",
       "x_7  0.052566  0.170274  0.145982  0.089306 -0.012482  0.240766 -0.002967   \n",
       "x_8 -0.036804 -0.275968  0.523582 -0.107552 -0.159761 -0.035146 -0.017424   \n",
       "x_9  0.144146  0.896043  0.932101  0.024791 -0.071360  0.223538  0.079374   \n",
       "\n",
       "          x_7       x_8       x_9  \n",
       "x_0  0.052566 -0.036804  0.144146  \n",
       "x_1  0.170274 -0.275968  0.896043  \n",
       "x_2  0.145982  0.523582  0.932101  \n",
       "x_3  0.089306 -0.107552  0.024791  \n",
       "x_4 -0.012482 -0.159761 -0.071360  \n",
       "x_5  0.240766 -0.035146  0.223538  \n",
       "x_6 -0.002967 -0.017424  0.079374  \n",
       "x_7  1.000000 -0.006442  0.171303  \n",
       "x_8 -0.006442  1.000000  0.179447  \n",
       "x_9  0.171303  0.179447  1.000000  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features that have high correlation.\n",
    "data_classification.drop(columns=[\"target\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "813dcac6-250c-4dcc-85cd-3f3669265547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gurkandurmus/anaconda3/envs/custom_base/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in true_divide\n",
      "  msw = sswn / float(dfwn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.406443</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>0.702296</td>\n",
       "      <td>1.637062</td>\n",
       "      <td>0.613154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057764</td>\n",
       "      <td>-0.055698</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>-0.398106</td>\n",
       "      <td>-0.393953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095807</td>\n",
       "      <td>0.425077</td>\n",
       "      <td>1.347864</td>\n",
       "      <td>-1.767760</td>\n",
       "      <td>0.516914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.075314</td>\n",
       "      <td>-0.369439</td>\n",
       "      <td>-0.294164</td>\n",
       "      <td>-0.551424</td>\n",
       "      <td>-0.167901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.807445</td>\n",
       "      <td>1.564458</td>\n",
       "      <td>0.962063</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>1.092314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.116028</td>\n",
       "      <td>0.914617</td>\n",
       "      <td>-0.535280</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>-1.739501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.953975</td>\n",
       "      <td>-1.753854</td>\n",
       "      <td>-1.021328</td>\n",
       "      <td>0.659155</td>\n",
       "      <td>-2.555383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.583881</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>1.128371</td>\n",
       "      <td>1.431660</td>\n",
       "      <td>-0.699556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.085207</td>\n",
       "      <td>1.830395</td>\n",
       "      <td>0.811040</td>\n",
       "      <td>-0.636988</td>\n",
       "      <td>0.432056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.082631</td>\n",
       "      <td>0.408684</td>\n",
       "      <td>0.041609</td>\n",
       "      <td>0.431081</td>\n",
       "      <td>0.921789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0  -1.406443  0.095395  0.702296  1.637062  0.613154\n",
       "1   0.057764 -0.055698  0.096949 -0.398106 -0.393953\n",
       "2  -0.095807  0.425077  1.347864 -1.767760  0.516914\n",
       "3  -1.075314 -0.369439 -0.294164 -0.551424 -0.167901\n",
       "4  -0.807445  1.564458  0.962063  0.066150  1.092314\n",
       "..       ...       ...       ...       ...       ...\n",
       "95  0.116028  0.914617 -0.535280  0.004435 -1.739501\n",
       "96 -0.953975 -1.753854 -1.021328  0.659155 -2.555383\n",
       "97 -0.583881 -0.006963  1.128371  1.431660 -0.699556\n",
       "98 -0.085207  1.830395  0.811040 -0.636988  0.432056\n",
       "99  0.082631  0.408684  0.041609  0.431081  0.921789\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features based on univariate feature selection\n",
    "from sklearn.feature_selection import chi2, f_classif, f_regression\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "\n",
    "class UnivariateFeatureSelection:\n",
    "    def __init__(self, n_features, problem_type, scoring):\n",
    "        \"\"\"\n",
    "        Custom univariate feature selection wrapper.\n",
    "        :param n_features: SelectPercentile if float else SelectKBest\n",
    "        :param problem_type: classification or regression\n",
    "        :param scoring: scoring function, string\n",
    "        \"\"\"\n",
    "        if problem_type == \"classification\":\n",
    "            valid_scoring = {\n",
    "                \"f_classif\": f_classif,\n",
    "                \"chi2\": chi2,\n",
    "                \"mutual_info_classif\": mutual_info_classif\n",
    "            }\n",
    "        \n",
    "        elif problem_type == \"regression\":\n",
    "            valid_scoring = {\n",
    "                \"f_regression\": f_classif,\n",
    "                \"mutual_info_regression\": mutual_info_classif\n",
    "            }\n",
    "        \n",
    "        if scoring not in valid_scoring:\n",
    "            raise Exception(f\"Invalid scoring function. Valid scorings are: {valid_scoring.keys()}\")\n",
    "            \n",
    "        if isinstance(n_features, int):\n",
    "            self.selection = SelectKBest(valid_scoring[scoring], k=n_features)\n",
    "        elif isinstance(n_features, float):\n",
    "            self.selection = SelectPercentile(valid_scoring[scoring], percentile=int(n_features*100))\n",
    "        else:\n",
    "            raise Exception(f\"n_features should be either float or int.\")\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self.selection.fit(X, y)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.selection.transform(X)\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        return self.selection.fit_transform(X,y)\n",
    "    \n",
    "ufs = UnivariateFeatureSelection(n_features=0.5, problem_type=\"regression\", scoring=\"f_regression\")\n",
    "ufs.fit(X=data_regression.drop(columns=[\"target\"]), y=data_regression[\"target\"])\n",
    "data_regression_transformed = ufs.transform(data_regression.drop(columns=[\"target\"]))\n",
    "pd.DataFrame(data_regression_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1196c620-f932-4f2d-8680-518815b995fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.1 ms, sys: 7.88 ms, total: 85 ms\n",
      "Wall time: 85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove features based on greedy feature selection\n",
    "from sklearn import metrics, linear_model\n",
    "\n",
    "class GreedyFeatureSelection:\n",
    "    \n",
    "    def evaluate_score(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: training data\n",
    "        :param y: targets\n",
    "        :return: overfitted area under the roc curve\n",
    "        \"\"\"\n",
    "        model = linear_model.LogisticRegression()\n",
    "        model.fit(X,y)\n",
    "        preds = model.predict_proba(X)[:, 1]\n",
    "        auc = metrics.roc_auc_score(y, preds)\n",
    "        \n",
    "        return auc\n",
    "    \n",
    "    def _feature_selection(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: data, numpy array\n",
    "        :param y: targets, numpy array\n",
    "        :return: (best_scores, best_features)\n",
    "        \"\"\"\n",
    "        good_features = []\n",
    "        best_scores = []\n",
    "        \n",
    "        num_features = X.shape[1]\n",
    "        state = True\n",
    "        while state:\n",
    "            best_score = 0\n",
    "            for feature in range(num_features):\n",
    "                if feature in good_features:\n",
    "                    continue\n",
    "                    \n",
    "                selected_features = good_features + [feature]\n",
    "                score = self.evaluate_score(X[:, selected_features], y)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_scores.append(best_score)\n",
    "                    good_features.append(feature)\n",
    "                \n",
    "            if len(best_scores) > 2:\n",
    "                if best_scores[-1] <= best_scores[-2]:\n",
    "                    state = False\n",
    "\n",
    "        return best_scores[:-1], good_features[:-1]\n",
    "        \n",
    "    def __call__(self, X, y):\n",
    "        scores, features = self._feature_selection(X, y)\n",
    "        \n",
    "        return X[:, features], scores\n",
    "\n",
    "X = data_classification.drop(columns=[\"target\"]).values\n",
    "y = data_classification[\"target\"].values\n",
    "\n",
    "X_transformed, scores = GreedyFeatureSelection()(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98495f10-7009-4b97-ba2c-e526945a311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69e0c15b-620a-4069-90b5-6ba4825cd640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5176, 0.9332, 0.984, 0.9868000000000001, 0.9884, 0.9896]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "720b24f9-7e0b-4a63-98d8-df48e7be8138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0bcac5f100>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaD0lEQVR4nO3deXCcdZ7f8fdXrcv3JVmWZGMb8G1sD+sxQ2CAGfBgjJE2maoUpCbJpDbDP8PObibZFGxtkQ1JKpWqVJJKFZsUyU7tTo4h1Gw2ahuDYThmFgYGy9At34wwh62WrfYtH7q6v/mjW3Yjy6gtd/fTx+dVpVI/Rz/PtxH+1FNP/57f19wdEREpfVVBFyAiIrmhQBcRKRMKdBGRMqFAFxEpEwp0EZEyUR3UiRsaGnzJkiVBnV5EpCTt2bPnpLs3jrctsEBfsmQJnZ2dQZ1eRKQkmdnn19umWy4iImViwkA3s5+YWZ+Z7bvOdjOz/2xm3WbWZWZ35r5MERGZSDZX6H8BbPmK7Y8Ay9I/TwL/5ebLEhGRGzVhoLv7r4DTX7FLO/BTT3kfmG1mzbkqUEREspOLe+itwNGM5WPpddcwsyfNrNPMOuPxeA5OLSIiowr6pai7v+DuG919Y2PjuKNuRERkknIR6D3Aoozlhel1IiJSQLkYhx4GnjKzF4G7gHPu3puD44pImXN3kg5Jd5LuuEMi6enl8bcn3Ukkr74e3f6lfZNX33PN9uSXj524cuzM91177szjjnfuRDJzefzaUnU7D65qYv2i2Tn/7zlhoJvZz4AHgAYzOwb8C6Am/cf4r8BOYCvQDVwC/lHOqxQpcu7OSNIZSTjDySQjCWckkWQ4mf6dcEZG14+zbjiRTK1PXg2H0WBLJFOhM976VMh4KpTSvxNJru474frRgMs8bmr9tee7/vpkRtBmnm80CDPXj4ZiIh18lcYM5s+sDybQ3f2JCbY78MOcVSQCXBgcoefM5atBd50AHE6MhmTyaqBe9z2p18PpsB19fyLp44fr2PePOU4iM7yTxZFMoSojZEZVFVTZ6GsjVGWp5fT61OvR9VxZvvK7ygil11dVGdVVVdRVX7s+dJ39r553vPNdu77KwNLLVRnHufJ6nO1mXDme2dXjXd336ue67vYvnWPMsaq+fO5Q5vaqL9dx5bOYYRnvu15t+RLYo/8iYw0MJ3j7cB/haIw3DvYxOJLMyXFDVUZ1lVETqqI6lAqnmpBRHTJqqq6uS/02qkNV1NdUUV1Xndovva0mVHVle80476n50rZr97v6/mvXXa3tarBcDcpUuIwGymhAjxfcUtkU6BKokUSS946coiMSY9e+4/QPjtAwvY4nNt3CxiVzqA1VTRCAo+F8NVCvhGx6Wz6viESKiQJdCs7d+fCLs2yPxtjRFePkhSFm1FWzZe0C2ja0cPet86gOaZohkRulQJeCOXT8POFIjHA0xrEzl6mrruLBVfNpW9/KAysaqa8JBV2iSElToEteHT19iXA0RjgS4/CJfkJVxr23N/DjzcvZvLqJGfU1QZcoUjYU6JJz8f5BXu6K0RGN8dEXZwH4+pI5/Kv2NWy9o5l50+uCLVCkTCnQJSfODwzz6r7jbI/GeLf7JEmHVc0zefqRlWxb18zCOVODLlGk7CnQZdIGhhO8cbCPcLSHtw7HGRpJsnjeVH74rdtpW9/CsqYZQZcoUlEU6HJDhhNJ3u0+STgS47UDJ7gwOELjjDq+d9di2ja0sH7hLA0TFAmIAl0mlEw6e744QzgS4+W9vZy+OMTM+moevaOZ9g0t3HXrPEJ6qEUkcAp0GZe7c7C3n45oDzuivfScvUx9TRUPrWqibX0L969opK5awwxFiokCXb7k81MXCUdSI1S6+y5QXWV8c1kDf/TwCjavbmJanf6XESlW+tcp9J0fYHtXL+FID9Fj5wDYtHQu//p317L1jmbmTqsNuEIRyYYCvUKduzTMK/t6CUdjvHfkFO6wtnUmf7x1JdvWtdAye0rQJYrIDVKgV5DLQwl+cfAEHZEYv/y4j+GEs7RhGj/69jLaNrRwW+P0oEsUkZugQC9zw4kkf/Pb+JVhhpeGEjTNrOMf3r2E9g2trG2dqWGGImVCgV6Gkknng89OE47GeGVvL2cuDTNrSg3tG1ppW9/CpqVzNcxQpAwp0MuEu7M/dp6OSA87unrpPTfAlJoQm1c30b6hhW8ua6S2WlPSipQzBXqJOxK/cGU2wyMnL1ITMu5f3sjTj6xk8+omptbqTyxSKfSvvQT1nrvMjmhqhMrennOYwTeWzuMH993KI2sXMHuqhhmKVCIFeok4c3GIV/YdpyPSwwefncYd1i2cxZ88uopt61pYMKs+6BJFJGAK9BLw0u6j/PFf72Uk6dzaOI0/fHA5bRtaWNowLejSRKSIKNCLnLvzZ293s2LBDP7dd9expkXDDEVkfBr2UOT29pzjs1OX+Ad3L2Ztq6amFZHrU6AXuY5IjNpQFVvWNAddiogUOQV6EUsknR1dMe5f0cisqWqmLCJfTYFexH7z6SlOnB+kfUNL0KWISAlQoBex7dEY02pDPLiyKehSRKQEKNCL1OBIgp17j/OdNQuYUqvOQCIyMQV6kfrVxyc5d3mYtvW63SIi2VGgF6lwNMacqTXcu6wh6FJEpEQo0IvQxcERXj9wnK13NFMT0p9IRLKjtChCvzh4goHhJO0bWoMuRURKSFaBbmZbzOywmXWb2dPjbF9sZm+YWZeZvW1mC3NfauXoiMRonlXPxsVzgi5FRErIhIFuZiHgeeARYDXwhJmtHrPbvwd+6u7rgOeAf5vrQivFmYtD/OrjOG3rW6hSVyERuQHZXKFvArrd/Yi7DwEvAu1j9lkNvJl+/dY42yVLO/f1MpJ0HtPoFhG5QdkEeitwNGP5WHpdpijwd9Kv/zYww8zmjT2QmT1pZp1m1hmPxydTb9kLR2Lc1jiNNS0zgy5FREpMrr4U/WfA/Wb2EXA/0AMkxu7k7i+4+0Z339jY2JijU5eP3nOX+eCz07Stb9WsiiJyw7KZD70HWJSxvDC97gp3j5G+Qjez6cB33f1sjmqsGDuivbhDm+ZuEZFJyOYKfTewzMyWmlkt8DgQztzBzBrMbPRYzwA/yW2ZlaEj2sP6hbPUiUhEJmXCQHf3EeApYBdwEHjJ3feb2XNm1pbe7QHgsJl9DDQB/yZP9ZatT+IX2NdzXl+GisikZdWCzt13AjvHrHs24/XPgZ/ntrTKEo7EMEOBLiKTpidFi4C7sz0a4xtL59E0sz7ockSkRCnQi8C+nvMcOXlRjSxE5KYo0ItAR6SHmpDxyFr1DRWRyVOgByyRdLZ3xbh/+Xz1DRWRm6JAD9gHn57mxPlBjT0XkZumQA9YOBpjam2Ih1bND7oUESlxCvQADY0k2bm3l82rm5ham9UIUhGR61KgB+hvfhvn3OVhjW4RkZxQoAeoIxJj9tQa7r1dE5WJyM1ToAfk0tAIrx84wdY7mqmt1p9BRG6ekiQgrx84weXhBG161F9EckSBHpDt0RgLZtazacncoEsRkTKhQA/A2UtD/PLjOI+tb1bfUBHJGQV6AF7Zd5zhhNO+YWwnPxGRyVOgB6Aj0sOt6hsqIjmmQC+w4+cG+M2np2lb36K+oSKSUwr0AtvRFUv1DdXoFhHJMQV6gXVEYtzROotbG6cHXYqIlBkFegEdiV9gb885PeovInmhQC+gcDTVN3TbOgW6iOSeAr1A3J1wNMZdS+eyYJb6hopI7inQC2R/7DxH4hdpW6+x5yKSHwr0AglHY+m+oQuCLkVEypQCvQCSSWd7NMZ9yxqZM6026HJEpEwp0Atg92en6T03oL6hIpJXCvQC6IjGmFITYvPqpqBLEZEypkDPM/UNFZFCUaDn2Tvdcc5eGtaj/iKSdwr0PAtHYsyaUsN9y9U3VETyS4GeR5eGRnhNfUNFpECUMnn0i4N9XBpS31ARKQwFeh6FI+m+oUvVN1RE8i+rQDezLWZ22My6zezpcbbfYmZvmdlHZtZlZltzX2ppSfUN7WPbumZC6hsqIgUwYaCbWQh4HngEWA08YWarx+z2J8BL7v414HHgz3JdaKl5VX1DRaTAsrlC3wR0u/sRdx8CXgTax+zjwGiDzFlALHcllqaOSIylDdNY26q+oSJSGNkEeitwNGP5WHpdpj8Fvmdmx4CdwO/npLoSdeL8AO9/ekp9Q0WkoHL1pegTwF+4+0JgK/A/zOyaY5vZk2bWaWad8Xg8R6cuPtuj6b6hmrtFRAoom0DvARZlLC9Mr8v0e8BLAO7+HlAPNIw9kLu/4O4b3X1jY2P5PmizPRpjbetMblPfUBEpoGwCfTewzMyWmlktqS89w2P2+QJ4EMDMVpEK9PK9BP8Kn568SPTYOY09F5GCmzDQ3X0EeArYBRwkNZplv5k9Z2Zt6d3+KfADM4sCPwO+7+6er6KL2fZ039DHFOgiUmBZTf/n7jtJfdmZue7ZjNcHgHtyW1rpcXc6Ij18fclcmmdNCbocEakwelI0hw70nueT+EXa9WWoiARAgZ5D4UiM6ipj69rmoEsRkQqkQM+RZNIJR2Pct1x9Q0UkGAr0HOn8/Ay95wZ0u0VEAqNAz5GOSA/1NVU8tEp9Q0UkGAr0HBhOjPYNXcC0OvUNFZFgKNBz4J3fnuSM+oaKSMAU6DkQjqb6ht6vvqEiEiAF+k26PJRg1/7jPLJ2gfqGikiglEA36Y1DJ1J9QzW6RUQCpkC/SR2RGPNn1HHX0nlBlyIiFU6BfhPOXRrml4fjPLa+RX1DRSRwCvSb8Or+XoYSSY1uEZGioEC/CeFojCXzprJu4aygSxERUaBPVt/5AX79ifqGikjxUKBP0o6uXvUNFZGiokCfpI5ojNXNM7l9/oygSxERARTok/LZyYtEj57VzIoiUlQU6JOwPRoDYJtGt4hIEVGg3yB3pyMaY9OSubTOVt9QESkeCvQbdLC3n+6+C/oyVESKjgL9BnVEe1J9Q+9Q31ARKS4K9BuQTDo7or18c1kDc9U3VESKjAL9Buz54gw9Zy/rdouIFCUF+g0IR2LU11SxefWCoEsREbmGAj1Lw4kkL+/t5cFVTUxX31ARKUIK9Cy9232S0xeHaNfYcxEpUgr0LIUjMWbWV3P/CvUNFZHipEDPwsDwaN/QZuqqQ0GXIyIyLgV6Ft442MdF9Q0VkSKnQM9CONpD44w6vnGr+oaKSPFSoE/g3OVh3joUZ9u6ZvUNFZGipkCfwK59xxlKJGnf0Bp0KSIiXymrQDezLWZ22My6zezpcbb/RzOLpH8+NrOzOa80IOFojMXzprJefUNFpMhN+ISMmYWA54HNwDFgt5mF3f3A6D7u/k8y9v994Gt5qLXg+voH+PUnJ/nht25X31ARKXrZXKFvArrd/Yi7DwEvAu1fsf8TwM9yUVzQXu7qJemoM5GIlIRsAr0VOJqxfCy97hpmthhYCrx586UFryMSY5X6hopIicj1l6KPAz9398R4G83sSTPrNLPOeDye41Pn1henLhFR31ARKSHZBHoPsChjeWF63Xge5ytut7j7C+6+0d03NjYW9yP04WjqIz6muVtEpERkE+i7gWVmttTMakmFdnjsTma2EpgDvJfbEgvP3emIxPj6kjnqGyoiJWPCQHf3EeApYBdwEHjJ3feb2XNm1pax6+PAi+7u+Sm1cA4d7+e3fRdo09W5iJSQrCb2dvedwM4x654ds/ynuSsrWOFojJD6hopIidGTomO4O+FIjHtvb2De9LqgyxERyZoCfYwP031DNbpFREqNAn2MjkiMuuoqvrNGfUNFpLQo0DOMJJK83NXLQ+obKiIlSIGe4d1PTnHq4pDGnotISVKgZ+iI9DCjvpoH1DdUREqQAj1tYDjBa/tPsGXNAupr1DdUREqPAj3tzUN9XBgcUSMLESlZCvS0cCRGw/Q67r5NfUNFpDQp0IHzA8O8ebhPfUNFpKQp0En3DR1J6mEiESlpCnRSc7fcMncqGxbNDroUEZFJq/hAj/cP8m73SdrWt6hvqIiUtIoP9Je7YiQd2nS7RURKXMUHejgaY+WCGSxvUt9QESltFR3oR09f4sMvzurqXETKQkUHejgaA+CxdQp0ESl9lR3okRi/s3gOi+ZODboUEZGbVrGBfuj4eQ6f6NfYcxEpGxUb6OGI+oaKSHmpyEB3d8LRGPfc3kCD+oaKSJmoyED/8IuzHDtzmTY1shCRMlKRgR6O9FBbXcXDa5qCLkVEJGcqLtBHEkle3tvLQ6vmM6O+JuhyRERypuIC/defnOLkhSHdbhGRslNxgR6OxphRV80DK+YHXYqISE5VVKAPDCfYte84D69V31ARKT8VFehvH+6jf3BEDxOJSFmqqEDviMRomF7L3beqb6iIlJ+KCfT+gWHeONTHtnUtVIcq5mOLSAWpmGTbtf8EQyNJHtPoFhEpUxUT6B2RHhbOmcKdt8wOuhQRkbyoiECP9w/y609OqW+oiJS1rALdzLaY2WEz6zazp6+zz981swNmtt/M/nduy7w5O/f2kkg67Rtagy5FRCRvqifawcxCwPPAZuAYsNvMwu5+IGOfZcAzwD3ufsbMiuqpnXA0xoqmGaxYoL6hIlK+srlC3wR0u/sRdx8CXgTax+zzA+B5dz8D4O59uS1z8o6evsSez8+ob6iIlL1sAr0VOJqxfCy9LtNyYLmZvWtm75vZlvEOZGZPmlmnmXXG4/HJVXyDtnel+oZq7hYRKXe5+lK0GlgGPAA8Afw3M5s9did3f8HdN7r7xsbGxhyd+quFIzHuvGW2+oaKSNnLJtB7gEUZywvT6zIdA8LuPuzunwIfkwr4QB0+3s+h4/26OheRipBNoO8GlpnZUjOrBR4HwmP2+X+krs4xswZSt2CO5K7MyQlHe6gyeHSdAl1Eyt+Ege7uI8BTwC7gIPCSu+83s+fMrC292y7glJkdAN4C/sjdT+Wr6Gxk9g1tnKG+oSJS/iYctgjg7juBnWPWPZvx2oEfp3+KwkdHz3L09GV+9O3A7/yIiBRE2T4pGo7EUn1D1y4IuhQRkYIoy0AfSSTZ0dXLt1fMZ6b6hopIhSjLQH//yGlOXhhUIwsRqShlGegdkR6m11XzrZVFNQOBiEhelV2gDwwneHXfcR5eo76hIlJZyi7Q3z4cp39wRHO3iEjFKbtAD0d7mDetlntuU99QEaksZRXo/QPDvHGwj0fXNatvqIhUnLJKvdf2n2BwJKnRLSJSkcoq0MPRGK2zp3DnLXOCLkVEpODKJtBPXRjkne6TtG1Q31ARqUxlE+ijfUM1Va6IVKqyCfSOSIzlTdNZqb6hIlKhyiLQj525ROfnZ2jf0KrbLSJSscoi0LdHewF4TI0sRKSClUWgh6MxvnbLbG6Zp76hIlK5Sj7QPz7Rz8He8/oyVEQqXskHejgSS/cNbQ66FBGRQJV0oI/2Df1btzUwf0Z90OWIiASqpAM9cvQsX5y+pJkVRUQo8UAPR2PUhqp4eI36hoqIlGygJ5LOjq5evrWykVlT1DdURKRkA/39I6eI9w/Str416FJERIpCyQZ6R6SHabUhHlylvqEiIlCigT44kuAV9Q0VEfmSkgz0tw/H6R9Q31ARkUwlGejhaIy502q55/aGoEsRESkaJRfoFwZH+MWBEzx6RzM16hsqInJFySXi6weOq2+oiMg4Si7Qp9fV8J3VTeobKiIyRnXQBdyozaub2Ly6KegyRESKTsldoYuIyPgU6CIiZSKrQDezLWZ22My6zezpcbZ/38ziZhZJ//zj3JcqIiJfZcJ76GYWAp4HNgPHgN1mFnb3A2N2/T/u/lQeahQRkSxkc4W+Ceh29yPuPgS8CLTntywREblR2QR6K3A0Y/lYet1Y3zWzLjP7uZktGu9AZvakmXWaWWc8Hp9EuSIicj25+lJ0O7DE3dcBrwN/Od5O7v6Cu290942NjY05OrWIiEB2gd4DZF5xL0yvu8LdT7n7YHrxvwO/k5vyREQkW9k8WLQbWGZmS0kF+ePA38vcwcya3b03vdgGHJzooHv27DlpZp/fYL2jGoCTk3xvqdJnrgz6zJXhZj7z4uttmDDQ3X3EzJ4CdgEh4Cfuvt/MngM63T0M/MjM2oAR4DTw/SyOO+l7LmbW6e4bJ/v+UqTPXBn0mStDvj5zVo/+u/tOYOeYdc9mvH4GeCa3pYmIyI3Qk6IiImWiVAP9haALCIA+c2XQZ64MefnM5u75OK6IiBRYqV6hi4jIGAp0EZEyUXKBPtHMj+XGzH5iZn1mti/oWgrFzBaZ2VtmdsDM9pvZHwRdU76ZWb2ZfWBm0fRn/pdB11QIZhYys4/MbEfQtRSCmX1mZnvTs9J25vz4pXQPPT3z48dkzPwIPDHOzI9lw8zuAy4AP3X3tUHXUwhm1gw0u/uHZjYD2AP8bpn/nQ2Y5u4XzKwGeAf4A3d/P+DS8srMfgxsBGa6+7ag68k3M/sM2OjueXmQqtSu0Ctu5kd3/xWph7Uqhrv3uvuH6df9pJ48Hm9CuLLhKRfSizXpn9K52poEM1sIPEpquhDJgVIL9GxnfpQyYWZLgK8Bvwm4lLxL336IAH3A6+5e7p/5PwH/HEgGXEchOfCame0xsydzffBSC3SpIGY2Hfgr4A/d/XzQ9eSbuyfcfQOpCfA2mVnZ3mIzs21An7vvCbqWArvX3e8EHgF+mL6lmjOlFugTzvwo5SF9H/mvgP/l7v836HoKyd3PAm8BWwIuJZ/uAdrS95RfBL5tZv8z2JLyz9170r/7gL8mdRs5Z0ot0K/M/GhmtaRmfgwHXJPkWPoLwj8HDrr7fwi6nkIws0Yzm51+PYXUF/+HAi0qj9z9GXdf6O5LSP07ftPdvxdwWXllZtPSX/JjZtOA7wA5Hb1WUoHu7iPA6MyPB4GX3H1/sFXll5n9DHgPWGFmx8zs94KuqQDuAf4+qau20cbjW4MuKs+agbfMrIvUhcvr7l4RQ/kqSBPwjplFgQ+Al9391VyeoKSGLYqIyPWV1BW6iIhcnwJdRKRMKNBFRMqEAl1EpEwo0EVEyoQCXUSkTCjQRUTKxP8H6O2yGOP5jpYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(scores)), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1699081f-57a7-45a3-bb8f-403a79f4c1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.406443</td>\n",
       "      <td>0.055370</td>\n",
       "      <td>0.120853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057764</td>\n",
       "      <td>0.106571</td>\n",
       "      <td>-0.371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095807</td>\n",
       "      <td>0.692119</td>\n",
       "      <td>-0.961747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.075314</td>\n",
       "      <td>-1.608192</td>\n",
       "      <td>1.054794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.807445</td>\n",
       "      <td>-0.589738</td>\n",
       "      <td>1.100733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.116028</td>\n",
       "      <td>-1.267179</td>\n",
       "      <td>0.324345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.953975</td>\n",
       "      <td>-0.748612</td>\n",
       "      <td>0.150141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.583881</td>\n",
       "      <td>-1.341429</td>\n",
       "      <td>-0.103101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.085207</td>\n",
       "      <td>1.070411</td>\n",
       "      <td>-0.114573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.082631</td>\n",
       "      <td>0.708994</td>\n",
       "      <td>0.597326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2\n",
       "0  -1.406443  0.055370  0.120853\n",
       "1   0.057764  0.106571 -0.371550\n",
       "2  -0.095807  0.692119 -0.961747\n",
       "3  -1.075314 -1.608192  1.054794\n",
       "4  -0.807445 -0.589738  1.100733\n",
       "..       ...       ...       ...\n",
       "95  0.116028 -1.267179  0.324345\n",
       "96 -0.953975 -0.748612  0.150141\n",
       "97 -0.583881 -1.341429 -0.103101\n",
       "98 -0.085207  1.070411 -0.114573\n",
       "99  0.082631  0.708994  0.597326\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove features based on recursive feature elimination\n",
    "from sklearn. feature_selection import RFE\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=3)\n",
    "\n",
    "X = data_regression.drop(columns=[\"target\"])\n",
    "y = data_regression[\"target\"]\n",
    "rfe.fit(X, y)\n",
    "\n",
    "X_transformed = rfe.transform(X)\n",
    "pd.DataFrame(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b130c21-6ee2-4ff3-ad68-bdfb8e6f8eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.406443</td>\n",
       "      <td>0.095395</td>\n",
       "      <td>0.702296</td>\n",
       "      <td>1.637062</td>\n",
       "      <td>0.613154</td>\n",
       "      <td>0.055370</td>\n",
       "      <td>-0.240875</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>1.507169</td>\n",
       "      <td>116.103673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057764</td>\n",
       "      <td>-0.055698</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>-0.398106</td>\n",
       "      <td>-0.393953</td>\n",
       "      <td>0.106571</td>\n",
       "      <td>1.763514</td>\n",
       "      <td>-0.371550</td>\n",
       "      <td>-0.984233</td>\n",
       "      <td>-0.315364</td>\n",
       "      <td>-79.898140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095807</td>\n",
       "      <td>0.425077</td>\n",
       "      <td>1.347864</td>\n",
       "      <td>-1.767760</td>\n",
       "      <td>0.516914</td>\n",
       "      <td>0.692119</td>\n",
       "      <td>-0.867617</td>\n",
       "      <td>-0.961747</td>\n",
       "      <td>1.899550</td>\n",
       "      <td>-0.790154</td>\n",
       "      <td>10.834235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.075314</td>\n",
       "      <td>-0.369439</td>\n",
       "      <td>-0.294164</td>\n",
       "      <td>-0.551424</td>\n",
       "      <td>-0.167901</td>\n",
       "      <td>-1.608192</td>\n",
       "      <td>0.457403</td>\n",
       "      <td>1.054794</td>\n",
       "      <td>-0.692943</td>\n",
       "      <td>0.614384</td>\n",
       "      <td>-192.035952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.807445</td>\n",
       "      <td>1.564458</td>\n",
       "      <td>0.962063</td>\n",
       "      <td>0.066150</td>\n",
       "      <td>1.092314</td>\n",
       "      <td>-0.589738</td>\n",
       "      <td>0.578448</td>\n",
       "      <td>1.100733</td>\n",
       "      <td>0.265488</td>\n",
       "      <td>-0.921710</td>\n",
       "      <td>79.689091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.116028</td>\n",
       "      <td>0.914617</td>\n",
       "      <td>-0.535280</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>-1.739501</td>\n",
       "      <td>-1.267179</td>\n",
       "      <td>-2.727517</td>\n",
       "      <td>0.324345</td>\n",
       "      <td>0.172801</td>\n",
       "      <td>-0.627018</td>\n",
       "      <td>-169.377685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.953975</td>\n",
       "      <td>-1.753854</td>\n",
       "      <td>-1.021328</td>\n",
       "      <td>0.659155</td>\n",
       "      <td>-2.555383</td>\n",
       "      <td>-0.748612</td>\n",
       "      <td>0.270809</td>\n",
       "      <td>0.150141</td>\n",
       "      <td>-0.221071</td>\n",
       "      <td>-0.079708</td>\n",
       "      <td>-210.255794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.583881</td>\n",
       "      <td>-0.006963</td>\n",
       "      <td>1.128371</td>\n",
       "      <td>1.431660</td>\n",
       "      <td>-0.699556</td>\n",
       "      <td>-1.341429</td>\n",
       "      <td>0.791885</td>\n",
       "      <td>-0.103101</td>\n",
       "      <td>1.025854</td>\n",
       "      <td>-0.537191</td>\n",
       "      <td>52.593579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.085207</td>\n",
       "      <td>1.830395</td>\n",
       "      <td>0.811040</td>\n",
       "      <td>-0.636988</td>\n",
       "      <td>0.432056</td>\n",
       "      <td>1.070411</td>\n",
       "      <td>-1.274225</td>\n",
       "      <td>-0.114573</td>\n",
       "      <td>-0.575302</td>\n",
       "      <td>0.138895</td>\n",
       "      <td>35.421726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.082631</td>\n",
       "      <td>0.408684</td>\n",
       "      <td>0.041609</td>\n",
       "      <td>0.431081</td>\n",
       "      <td>0.921789</td>\n",
       "      <td>0.708994</td>\n",
       "      <td>-0.640788</td>\n",
       "      <td>0.597326</td>\n",
       "      <td>-1.038590</td>\n",
       "      <td>1.489848</td>\n",
       "      <td>121.546467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
       "0  -1.406443  0.095395  0.702296  1.637062  0.613154  0.055370 -0.240875   \n",
       "1   0.057764 -0.055698  0.096949 -0.398106 -0.393953  0.106571  1.763514   \n",
       "2  -0.095807  0.425077  1.347864 -1.767760  0.516914  0.692119 -0.867617   \n",
       "3  -1.075314 -0.369439 -0.294164 -0.551424 -0.167901 -1.608192  0.457403   \n",
       "4  -0.807445  1.564458  0.962063  0.066150  1.092314 -0.589738  0.578448   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.116028  0.914617 -0.535280  0.004435 -1.739501 -1.267179 -2.727517   \n",
       "96 -0.953975 -1.753854 -1.021328  0.659155 -2.555383 -0.748612  0.270809   \n",
       "97 -0.583881 -0.006963  1.128371  1.431660 -0.699556 -1.341429  0.791885   \n",
       "98 -0.085207  1.830395  0.811040 -0.636988  0.432056  1.070411 -1.274225   \n",
       "99  0.082631  0.408684  0.041609  0.431081  0.921789  0.708994 -0.640788   \n",
       "\n",
       "         x_7       x_8       x_9      target  \n",
       "0   0.120853  0.190918  1.507169  116.103673  \n",
       "1  -0.371550 -0.984233 -0.315364  -79.898140  \n",
       "2  -0.961747  1.899550 -0.790154   10.834235  \n",
       "3   1.054794 -0.692943  0.614384 -192.035952  \n",
       "4   1.100733  0.265488 -0.921710   79.689091  \n",
       "..       ...       ...       ...         ...  \n",
       "95  0.324345  0.172801 -0.627018 -169.377685  \n",
       "96  0.150141 -0.221071 -0.079708 -210.255794  \n",
       "97 -0.103101  1.025854 -0.537191   52.593579  \n",
       "98 -0.114573 -0.575302  0.138895   35.421726  \n",
       "99  0.597326 -1.038590  1.489848  121.546467  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45538e3a-2a6e-46a6-9954-2b290ac37823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGDCAYAAAAVnQglAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj8klEQVR4nO3dfbxdVX3n8c+XCEkkPEMdBDVacawSJrYgtZaqVKtTxtG2WrUqYjtDrZ2hndZOmbFMGYrT4FT7MM6MpFOHJgFrpcorGp+oUesYaRMU86BVgcZCZEREo4BkQvjNH3tHjpf7cG7uCWdx7+f9ep3X3Wfvddb+rbvPvb+71ll37VQVkiRp/A4ZdwCSJKljUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVpHkjyH5P8r3HHIWlu4v8pa6FLshN4FLBvYPeTquqrc6zzX1XVX88tuoefJBcDT6yqV407Funhxp6y1HlhVS0beBxwQh6FJI8Y5/kP1MM1bqkVJmVpCkmOSvJnSW5LsivJpUkW9cd+MMnGJN9IckeSK5Mc3R9bCzwWeF+Su5L8+yTPTnLrhPp3Jnluv31xkquTrEvybeC86c4/SawXJ1nXby9PUklem+SWJN9M8rokZyTZmuRbSd428NrzknwqyduS7E7y90l+cuD4o5OsT3JnkhuT/OsJ5x2M+3XAfwRe1rf9c3251yb5QpLvJLk5yS8P1PHsJLcm+c0kt/ftfe3A8aVJ3pLkK318/yfJ0v7YjybZ1Lfpc0mePaFdN/fn/Ickr5zVG0AaA/+qlaZ2BXA78ETgcOD9wC3A5UCA3wf+BjgS+CvgYuDXq+rVSc5iYPh6MFlM40XAS4FzgcXAVdOcfxhnAqcAPwGsBz4EPBc4FPhskndX1ScGyl4NHA/8LPCeJI+vqjuBvwC2A48Gngxcm+Smqto4RdzH8+Dh69uBfwHc3MfzwSSbq+oz/fF/AhwFnAQ8D7g6yTVV9U3gD4CnAj8G/N8+1vuTnARsAF7dt+0ngb9K8mTgHuBPgDOq6otJTgSOHfL7Jo2NPWWpc03f2/pWkmuSPAr4aboke3dV3Q78IfBygKq6saqurao9VfV14K3As+YYw6er6pqqup8u0U95/iH9XlXdW1UfAe4G3llVt1fVLuCTwNMGyt4O/FFV7a2qdwFfBM5J8hjgmcBv93XdAPwvugT8oLir6ruTBVJVG6rqpup8AvgIcNZAkb3AJf35PwDcBfzTJIcAvwj8WlXtqqp9VbWpqvYArwI+UFUf6M99LbCl/74B3A+cmmRpVd1WVTtm8b2TxsKestR58eCkrCRPp+tR3pZk/+5D6Hqq9En7j+kSyxH9sW/OMYZbBrYfN935h/S1ge3vTvJ82cDzXfX9sz6/QtczfjRwZ1V9Z8Kx06eIe1JJ/jnwu8CT6NrxSGDbQJFvVNV9A8/v6eM7HlgC3DRJtY8DXprkhQP7DgU+VlV3J3kZ8Abgz5J8CvjNqvr7mWKVxsmesjS5W4A9wPFVdXT/OLKqntof/y9AASuq6ki6XlsGXj/x3xrupktEAPSfDZ8woczga2Y6/6idlIHsT/eZ+Ff7x7FJjphwbNcUcT/oeZLFdMP7fwA8qqqOBj7A93+/pnIHcC/wg5McuwVYO/D9ObqqDq+qVQBV9eGqeh5wIvD3wJ8OcT5prEzK0iSq6ja6Ida3JDkyySH95K79Q9RH0A2x7u4/2/ytCVV8DXjCwPMvAUuSnJPkUOB36D5/PdDzj9oPABckOTTJS4EfohsavgXYBPx+kiVJTgN+CVg3TV1fA5b3Q88Ah9G19evAfX2v+aeGCaofyn8H8NZ+wtmiJM/oE/064IVJnt/vX9JPGjs5yaOSvCjJ4XR/3NxFN5wtNc2kLE3tXLqE8nm6oemr6XpdAP8Z+GFgN91ko/dMeO3vA7/Tf0b9hqraDbye7vPYXXQ951uZ3nTnH7W/pZsUdgfwJuAlVfWN/tgrgOV0veb3Ar87w/9fv7v/+o0kn+mHvi8A/pKuHb9AN/FsWG+gG+reDNwJXAYc0v/B8CK62d5fp+s5/xbd77VDgN/oY76T7vP+X5nFOaWxcPEQaYFLch7dTPEfH3cs0kJnT1mSpEaYlCVJaoTD15IkNcKesiRJjTApS5LUiLGu6HX88cfX8uXLxxmCJEkPqeuvv/6Oqpq4eBAw5qS8fPlytmzZMs4QJEl6SCX5ylTHHL6WJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaMdYbUmzbtZvlF24YZwiSJE1p56pzHtLz2VOWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREjS8pJLkuyvX+8bFT1SpK0UIxkmc0k5wA/DKwEFgMfT/LBqvr2KOqXJGkhmLannOSMJFuTLElyeJIdSU6dpOhTgL+pqvuq6m5gK/CCgxGwJEnz1bRJuao2A+uBS4E3A+uqavskRT8HvCDJI5McDzwHeMxkdSY5P8mWJFv23bN7btFLkjSPDDN8fQmwGbgXuGCyAlX1kSRnAJuArwOfBvZNUXY1sBpg8Ymn1AHELEnSvDTMRK/jgGXAEcCSqQpV1ZuqamVVPQ8I8KXRhChJ0sIwTFK+HLgIuBK4bLICSRYlOa7fPg04DfjIqIKUJGkhmHb4Osm5wN6quirJImBTkrOrauOEoocCn0wC8G3gVVV130GJWJKkeWrapFxVa4A1/fY+4Mwpyt1LNwNbkiQdIFf0kiSpEbNaPCTJCmDthN17qmrSHrQkSRrerJJyVW2jW7VLkiSNmMPXkiQ1wqQsSVIjTMqSJDViJHeJOlArTjqKLavOGWcIkiQ1w56yJEmNMClLktQIk7IkSY0wKUuS1AiTsiRJjRjr7Ottu3az/MIN4wxBkuadnf5Xy8OWPWVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREjTcpJ3pxkR5IvJPmTJBll/ZIkzWcjS8pJfgx4JnAacCpwBvCsUdUvSdJ8N2NSTnJGkq1JliQ5vO8JnzpJ0QKWAIcBi4FDga+NNlxJkuavGde+rqrNSdYDlwJLgXVVtX2Scp9O8jHgNiDA26rqCxPLJTkfOB9g0ZEnzDF8SZLmj2GHry8BngecDrx5sgJJngj8EHAycBJwdpKzJparqtVVdXpVnb7okUcdWNSSJM1Dwybl44BlwBF0Q9ST+Rnguqq6q6ruAj4IPGPuIUqStDAMm5QvBy4CrgQum6LMPwLPSvKIJIfSTfJ60PC1JEma3IyfKSc5F9hbVVclWQRsSnJ2VW2cUPRq4GxgG92krw9V1ftGHrEkSfPUMBO91gBr+u19wJlTlNsH/PJIo5MkaQFxRS9JkhoxY095oiQrgLUTdu+pqkl70JIkaTizTspVtQ1YOfpQJEla2By+liSpESZlSZIaYVKWJKkRs/5MeZRWnHQUW1adM84QJElqhj1lSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGjHW2dfbdu1m+YUbxhmCpHlsp//doYcZe8qSJDXCpCxJUiNMypIkNcKkLElSI0zKkiQ1wqQsSVIjTMqSJDXCpCxJUiNMypIkNWIkSTnJc5LcMPC4N8mLR1G3JEkLxUiW2ayqjwErAZIcC9wIfGQUdUuStFBM21NOckaSrUmWJDk8yY4kp85Q50uAD1bVPVPUeX6SLUm27Ltn94HGLUnSvDNtT7mqNidZD1wKLAXWVdX2Gep8OfDWaepcDawGWHziKTW7cCVJmr+GGb6+BNgM3AtcMF3BJCcCK4APzz00SZIWlmEmeh0HLAOOAJbMUPbngfdW1d65BiZJ0kIzTFK+HLgIuBK4bIayrwDeOdegJElaiKYdvk5yLrC3qq5KsgjYlOTsqto4SdnlwGOATxyUSCVJmudmmui1BljTb+8Dzpym7E7gpFEGJ0nSQuKKXpIkNWJWi4ckWQGsnbB7T1VN2YOWJEnDmVVSrqpt9Ct3SZKk0XL4WpKkRpiUJUlqxEhuSHGgVpx0FFtWnTPOECRJaoY9ZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhox1tnX23btZvmFG8YZgqSH0E7/20Kalj1lSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhoxsqSc5LFJPpLkC0k+n2T5qOqWJGkhGOUym2uAN1XVtUmWAfePsG5Jkua9aXvKSc5IsjXJkiSHJ9mR5NRJyj0FeERVXQtQVXdV1T1T1Hl+ki1Jtuy7Z/dIGiFJ0nwwbU+5qjYnWQ9cCiwF1lXV9kmKPgn4VpL3AI8H/hq4sKr2TVLnamA1wOITT6k5xi9J0rwxzPD1JcBm4F7ggmnqOQt4GvCPwLuA84A/m3uIkiQtDMNM9DoOWAYcASyZosytwA1VdXNV3QdcA/zwSCKUJGmBGCYpXw5cBFwJXDZFmc3A0UlO6J+fDXx+7uFJkrRwTDt8neRcYG9VXZVkEbApydlVtXGwXFXtS/IG4KNJAlwP/OlBi1qSpHlopolea+j+1Yl+0taZ05S9FjhtpNFJkrSAuKKXJEmNmNXiIUlWAGsn7N5TVVP2oCVJ0nBmlZSrahuw8uCEIknSwubwtSRJjTApS5LUiFHekGLWVpx0FFtWnTPOECRJaoY9ZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhox1tnX23btZvmFG8YZgrRg7fQ/H6Tm2FOWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREjW9EryT5gW//0H6vqX46qbkmSFoJRLrP53apaOcL6JElaUKYdvk5yRpKtSZYkOTzJjiSnPlTBSZK0kEzbU66qzUnWA5cCS4F1VbV9iuJLkmwB7gNWVdU1kxVKcj5wPsCiI0840LglSZp3hhm+vgTYDNwLXDBNucdV1a4kTwA2JtlWVTdNLFRVq4HVAItPPKUOIGZJkualYWZfHwcsA44AlkxVqKp29V9vBj4OPG0E8UmStGAMk5QvBy4CrgQum6xAkmOSLO63jweeCXx+VEFKkrQQTDt8neRcYG9VXZVkEbApydlVtXFC0R8CLk9yP12iX1VVJmVJkmZhpolea4A1/fY+4Mwpym0CVow8OkmSFhBX9JIkqRGzWjwkyQpg7YTde6pq0h60JEka3qySclVtA1YenFAkSVrYHL6WJKkRJmVJkhphUpYkqRGjvEvUrK046Si2rDpnnCFIktQMe8qSJDXCpCxJUiNMypIkNcKkLElSI0zKkiQ1Yqyzr7ft2s3yCzeMMwTpIbXT/zaQNA17ypIkNcKkLElSI0zKkiQ1wqQsSVIjTMqSJDXCpCxJUiNMypIkNcKkLElSI0aelJMcmeTWJG8bdd2SJM1nB6On/HvA3xyEeiVJmtdmTMpJzkiyNcmSJIcn2ZHk1CnK/gjwKOAjow5UkqT5bsa1r6tqc5L1wKXAUmBdVW2fWC7JIcBbgFcBz52qviTnA+cDLDryhAMMW5Kk+WfYG1JcAmwG7gUumKLM64EPVNWtSaasqKpWA6sBFp94Sg0fqiRJ89uwSfk4YBlwKLAEuHuSMs8Azkry+r7sYUnuqqoLRxKpJEnz3LBJ+XLgIuDxwGXAv5lYoKpeuX87yXnA6SZkSZKGN2NSTnIusLeqrkqyCNiU5Oyq2njww5MkaeEYZqLXGmBNv70POHOI11wBXDHH2CRJWlBc0UuSpEYM+5ny9yRZAaydsHtPVc3Yg5YkSVObdVKuqm3AytGHIknSwubwtSRJjTApS5LUCJOyJEmNmPVnyqO04qSj2LLqnHGGIElSM+wpS5LUCJOyJEmNMClLktQIk7IkSY0wKUuS1Iixzr7etms3yy/cMM4QdIB2OmtekkbOnrIkSY0wKUuS1AiTsiRJjTApS5LUCJOyJEmNMClLktQIk7IkSY0wKUuS1AiTsiRJjRhZUk7yuCSfSXJDkh1JXjequiVJWghGuczmbcAzqmpPkmXA9iTrq+qrIzyHJEnz1ow95SRnJNmaZEmSw/te8KkTy1XV/6uqPf3TxVPVneT8JFuSbNl3z+65RS9J0jwyY0+5qjYnWQ9cCiwF1lXV9snKJnkMsAF4IvBbk/WSq2o1sBpg8Ymn1BxilyRpXhl2+PoSYDNwL3DBVIWq6hbgtCSPBq5JcnVVfW3uYUqSNP8NO9HrOGAZcASwZKbCfQ95O3DWgYcmSdLCMmxSvhy4CLgSuGyyAklOTrK03z4G+HHgi6MIUpKkhWDG4esk5wJ7q+qqJIuATUnOrqqNE4r+EPCWJAUE+IOq2jb6kCVJmp+Gmei1BljTb+8Dzpyi3LXAaSONTpKkBcQVvSRJasSsFw9JsgJYO2H3nqqatActSZKGM+uk3H9OvHL0oUiStLA5fC1JUiNMypIkNWKUN6SYtRUnHcWWVeeMMwRJkpphT1mSpEaYlCVJaoRJWZKkRpiUJUlqhElZkqRGjHX29bZdu1l+4YZxhrBg7XTWuyQ1x56yJEmNMClLktQIk7IkSY0wKUuS1AiTsiRJjTApS5LUCJOyJEmNMClLktQIk7IkSY0YSVJOsjLJp5PsSLI1yctGUa8kSQvJqJbZvAc4t6q+nOTRwPVJPlxV3xpR/ZIkzXvT9pSTnNH3fJckObzvCZ86sVxVfamqvtxvfxW4HThhijrPT7IlyZZ99+weRRskSZoXpu0pV9XmJOuBS4GlwLqq2j7da5I8HTgMuGmKOlcDqwEWn3hKHUjQkiTNR8MMX18CbAbuBS6YrmCSE4G1wGuq6v65hydJ0sIxzESv44BlwBHAkqkKJTkS2AC8saquG014kiQtHMMk5cuBi4ArgcsmK5DkMOC9wJqqunp04UmStHBMO3yd5Fxgb1VdlWQRsCnJ2VW1cULRnwd+AjguyXn9vvOq6oZRByxJ0nw100SvNcCafnsfcOYU5dYB60YenSRJC4grekmS1IhZLR6SZAXd7OpBe6pq0h60JEka3qySclVtA1YenFAkSVrYHL6WJKkRJmVJkhoxqhtSHJAVJx3FllXnjDMESZKaYU9ZkqRGmJQlSWqESVmSpEaYlCVJaoRJWZKkRpiUJUlqxFj/JWrbrt0sv3DDOENoyk7/PUySFjR7ypIkNcKkLElSI0zKkiQ1wqQsSVIjTMqSJDXCpCxJUiNMypIkNcKkLElSI0aWlJN8KMm3krx/VHVKkrSQjLKn/F+BV4+wPkmSFpRpk3KSM5JsTbIkyeFJdiQ5dbKyVfVR4DsHJUpJkhaAade+rqrNSdYDlwJLgXVVtX0uJ0xyPnA+wKIjT5hLVZIkzSvD3JDiEmAzcC9wwVxPWFWrgdUAi088peZanyRJ88UwnykfBywDjgCWHNxwJElauIZJypcDFwFXApcd3HAkSVq4ph2+TnIusLeqrkqyCNiU5Oyq2jhJ2U8CTwaWJbkV+KWq+vBBiVqSpHlopolea4A1/fY+4Mxpyp412tAkSVpYXNFLkqRGDDP7+nuSrADWTti9p6qm7EFLkqThzCopV9U2YOXBCUWSpIXN4WtJkhphUpYkqREmZUmSGjGrz5RHbcVJR7Fl1TnjDEGSpGbYU5YkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRY519vW3XbpZfuGGcIYzcTmeTS5IOkD1lSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRI03KSV6T5Mv94zWjrFuSpPluZCt6JTkW+F3gdKCA65Osr6pvjuockiTNZzP2lJOckWRrkiVJDk+yI8mpkxR9PnBtVd3ZJ+JrgReMOmBJkuarGXvKVbU5yXrgUmApsK6qtk9S9CTgloHnt/b7vk+S84HzARYdecKBxCxJ0rw07PD1JcBm4F7ggrmcsKpWA6sBFp94Ss2lLkmS5pNhJ3odBywDjgCWTFFmF/CYgecn9/skSdIQhk3KlwMXAVcCl01R5sPATyU5JskxwE/1+yRJ0hBmHL5Oci6wt6quSrII2JTk7KraOFiuqu5M8nt0w9wAl1TVnaMPWZKk+WmYiV5rgDX99j7gzGnKvgN4x8iikyRpAXFFL0mSGjHrxUOSrADWTti9p6qm7EFLkqSZzTopV9U2YOXoQ5EkaWFz+FqSpEaYlCVJaoRJWZKkRozsLlEHYsVJR7Fl1TnjDEGSpGbYU5YkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhphUpYkqREmZUmSGpGqGt/Jk+8AXxxbAKN1PHDHuIMYEdvSJtvSJtvSppbb8riqOmGyA2O9nzLwxao6fcwxjESSLbalPbalTbalTbZl/By+liSpESZlSZIaMe6kvHrM5x8l29Im29Im29Im2zJmY53oJUmSHjDunrIkSeqNNCkneUGSLya5McmFkxxfnORd/fG/TbJ84Nh/6Pd/Mcnzh63zYDnQtiR5XpLrk2zrv5498JqP93Xe0D9+oPG2LE/y3YF43z7wmh/p23hjkj9Jksbb8sqBdtyQ5P4kK/tjrV6Xn0jymST3JXnJhGOvSfLl/vGagf0P+XU50HYkWZnk00l2JNma5GUDx65I8g8D12TlwW7HXNrSH9s3EO/6gf2P79+LN/bvzcNabkuS50z4Wbk3yYv7Y61el99I8vn+ffTRJI8bONbMz8pQqmokD2ARcBPwBOAw4HPAUyaUeT3w9n775cC7+u2n9OUXA4/v61k0TJ0H4zHHtjwNeHS/fSqwa+A1HwdOP9jxj7Aty4HtU9T7d8CPAgE+CPzzltsyocwK4KaHwXVZDpwGrAFeMrD/WODm/usx/fYx47guc2zHk4BT+u1HA7cBR/fPrxgs2/o16Y/dNUW9fwm8vN9+O/ArrbdlwnvtTuCRjV+X5wzE+Cs88DusmZ+VYR+j7Ck/Hbixqm6uqv8H/AXwogllXgT8eb99NfCT/V8nLwL+oqr2VNU/ADf29Q1T58FwwG2pqs9W1Vf7/TuApUkWPwQxT2Uu12VSSU4Ejqyq66p7d68BXjzyyB9sVG15Rf/acZqxLVW1s6q2AvdPeO3zgWur6s6q+iZwLfCCMV2XA25HVX2pqr7cb38VuB2YdEGFh8hcrsmk+vfe2XTvRejemy8eWcRTG1VbXgJ8sKruOXihzmiYtnxsIMbrgJP77ZZ+VoYyyqR8EnDLwPNb+32Tlqmq+4DdwHHTvHaYOg+GubRl0M8Bn6mqPQP7/nc/7HPRQzRcMte2PD7JZ5N8IslZA+VvnaHOg2FU1+VlwDsn7Gvxusz2teO4LiP5GU3ydLpe0E0Du9/UD0f+4UP0h+1c27IkyZYk1+0f7qV7732rfy8eSJ0HalS/O1/Og39WWr8uv0TX853uteP6HTYjJ3odJEmeClwG/PLA7ldW1QrgrP7x6nHENgu3AY+tqqcBvwFcleTIMcc0J0nOBO6pqu0Dux9u12Ve6Xsta4HXVtX+Xtt/AJ4MnEE39PjbYwpvNh5X3QpSvwD8UZIfHHdAc9FflxXAhwd2N31dkrwKOB34r+OO5UCNMinvAh4z8Pzkft+kZZI8AjgK+MY0rx2mzoNhLm0hycnAe4Fzq+p7f/lX1a7+63eAq+iGZQ62A25L/3HCNwCq6nq6XsyT+vInD7z+YXFdeg/6y7/h6zLb147juszpZ7T/I28D8Maqum7//qq6rTp7gP9N+9dk8H10M908hafRvfeO7t+Ls65zDkbxu/PngfdW1d79O1q+LkmeC7wR+JcDo5Mt/awMZ1QfTtOto30z3USt/R/GP3VCmV/l+yfh/GW//VS+f6LXzXQf7s9Y58F4zLEtR/flf3aSOo/vtw+l+4zpdY235QRgUb/9BLo37bE1+SSJn265Lf3zQ/o2POHhcF0Gyl7Bgyd6/QPdxJVj+u2xXJc5tuMw4KPAr09S9sT+a4A/AlY1fk2OARb328cDX6afjAS8m++f6PX6ltsysP864DkPh+tC9wfQTfQTBwf2N/OzMnR7R/zN+2ngS/035439vkvo/nIBWNK/QW/svyGDvxzf2L/uiwzMgpuszofkG3OAbQF+B7gbuGHg8QPA4cD1wFa6CWB/TJ/wGm7Lz/Wx3gB8BnjhQJ2nA9v7Ot9GvxBNq23pjz0buG5CfS1flzPoPuu6m67HtWPgtb/Yt/FGumHfsV2XA20H8Cpg74SflZX9sY3Atr4t64BlLV8T4Mf6eD/Xf/2lgTqf0L8Xb+zfm4tbbkt/bDndH7CHTKiz1evy18DXBt5H61v8WRnm4YpekiQ1wolekiQ1wqQsSVIjTMqSJDXCpCxJUiNMypIkNcKkrOYM3G1ne5L3JTl6RPWel+Rto6hrQr0T7zL1kplfdUDnWZ7kF6Y5NnhHrxsO5G5E/ffo0XOPdtK6n53k/Qej7hnO+WMP5TmluTApq0XfraqVVXUq3R1qfnXcAQ3hlX3MK6vq6pmLf2/FsdlYTreE41RuGohhZXWL98/WeXR3bBraAbTjIdHH9Wy6/yGWHhZMymrdp+kXik/y9HT33/1skk1J/mm//7wk70nyof6eqW/e/+Ikr03ypSR/BzxzYP/yJBsH7r/62H7/FUn+Z39TgZv7ntY7knwhyRXDBp3k2CTX9PVfl+S0fv/FSdYm+RSwNskJSf4qyeb+8cy+3LMGeryfTXIEsAo4q9/374aM46f679lnkrw7ybJ+/3/qz7c9yep0XkK3oMKV/TmWJtmZ5Pj+Nacn+fhs2jFNXBcn+fMkn0zylSQ/m+TN6e5v+6Ekh/bldg7s/7skTxzi+r09yd/S3TLxdcC/69tzVpIXpru38WeT/HWSRw3E8450ox43J7lgINZz+/N8Lsnaft9srps0vHGvXuLDx8QH/X1p6ZZafTfwgv75kcAj+u3nAn/Vb59HtwzfUXQren2Fbr3bE4F/pFsu9DDgU8Db+te8D3hNv/2LwDX99hV0t4bbf0vRb9Mtyn8I3cpfKyeJ9+N0K9Hd0D+OA/4b8Lv98bOBG/rti/t6lvbPrwJ+vN9+LPCFgfie2W8vo1tq8NnA+6f4ni0HvjsQw3+nW+7xb4DD+zK/DfynfvvYgdeupV+tjQn3lgZ28sAypKcDH59NOybE+L34+9f/H7qlTf8ZcA/9Sn5068a/eOD8+1dwOnfg9dNdv/fzwPKwFwNvGIjhGPjeokn/CnjLQLlNdEv9Hk+3wtWhdEsAf2nge3DsdO2d7LqN++fJx8Pr0eSwkxa8pUluoOshf4HuHqjQJd0/T3IKUHS/NPf7aFXtBkjyeeBxdL9cP15VX+/3v4vuhhoAzwB+tt9eC7x5oK73VVUl2QZ8raq29a/fQZf8bpgk5ldW1Zb9T5L8ON0ypVTVxiTH5YE7bK2vqu/2288FnpIH7hZ5ZN+b/RTw1iRXAu+pqlsz8x0lb6qqlQMx/AvgKcCn+tceRjfyAPCcJP8eeCTd+sA76BLKbMzYjqq6a5rXf7Cq9vbf50XAh/r92+i+z/u9c+DrH/bb012/d1fVvinOeTLwrnR3QDqMbi3k/TZUdyODPUluBx5F9wfVu6vqDoCqunO69jLJdZum/dKDmJTVou9W1cokj6S7bdyvAn8C/B7wsar6mSTL6Xp1+w3es3ofc3tv76/r/gn13j/Heve7e2D7EOBHq+reCWVWJdlAt+bvp5I8/wDOE7obvL/i+3YmS4D/QdcjviXJxXQjDJO5jwc+5ppYZph2TGcPQFXdn2RvVe1f83fi97mm2J7K3dMc+2/AW6tqfZJn0/WQvy+e3kzvoaGvW1X9/RAxS4CfKathVXUPcAHwm3ngNoz7b6923hBV/C3wrL6Xeijw0oFjm+juIgXwSuCTIwn6AZ/s66X/5X9HVX17knIfAf7t/idJVvZff7CqtlXVZcBmunvYfgeYzWeU1wHPHPgc9vAkT+KB5HpH37sbnC0+8Rw7gR/pt39umnNN2o4RednA1/09/WGv38T2DL6HXjPEuTcCL01yHHRzBfr9s7lu0tBMympaVX2W7g5Or6Abovz9JJ9liB5rVd1G1xP6NN2w4hcGDv9b4LVJtgKvBn5ttJFzMfAjff2rmDoBXACc3k8k+jzdxCSAX083CWsr3Z2UPkj3fdjXTziacaJXP2x/HvDOvp5PA0+uqm8Bf0p3h5wP0yWP/a4A3t5PVFoK/Gfgj5Nsoes9TmWqdozCMX38vwbsb/ew1+99wM/sn+hFd13eneR64I6ZTlxVO4A3AZ9I8jngrf2h2Vw3aWjeJUpSs5LspBtmnzGBSvOBPWVJkhphT1mSpEbYU5YkqREmZUmSGmFSliSpESZlSZIaYVKWJKkRJmVJkhrx/wEy6MFTge98XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove features based on the feature importance\n",
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestRegressor()\n",
    "model.fit(X,y)\n",
    "importances = model.feature_importances_\n",
    "idx = np.argsort(importances)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(len(idx)), importances[idx], align=\"center\")\n",
    "plt.yticks(range(len(idx)), [data_regression.columns[col] for col in range(len(idx))])\n",
    "plt.xlabel(\"Random Forest Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5eb5d8f-75e8-43a9-8750-c208ae2b8ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055370</td>\n",
       "      <td>0.190918</td>\n",
       "      <td>1.507169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106571</td>\n",
       "      <td>-0.984233</td>\n",
       "      <td>-0.315364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692119</td>\n",
       "      <td>1.899550</td>\n",
       "      <td>-0.790154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.608192</td>\n",
       "      <td>-0.692943</td>\n",
       "      <td>0.614384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.589738</td>\n",
       "      <td>0.265488</td>\n",
       "      <td>-0.921710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.267179</td>\n",
       "      <td>0.172801</td>\n",
       "      <td>-0.627018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.748612</td>\n",
       "      <td>-0.221071</td>\n",
       "      <td>-0.079708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.341429</td>\n",
       "      <td>1.025854</td>\n",
       "      <td>-0.537191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.070411</td>\n",
       "      <td>-0.575302</td>\n",
       "      <td>0.138895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.708994</td>\n",
       "      <td>-1.038590</td>\n",
       "      <td>1.489848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_5       x_8       x_9\n",
       "0   0.055370  0.190918  1.507169\n",
       "1   0.106571 -0.984233 -0.315364\n",
       "2   0.692119  1.899550 -0.790154\n",
       "3  -1.608192 -0.692943  0.614384\n",
       "4  -0.589738  0.265488 -0.921710\n",
       "..       ...       ...       ...\n",
       "95 -1.267179  0.172801 -0.627018\n",
       "96 -0.748612 -0.221071 -0.079708\n",
       "97 -1.341429  1.025854 -0.537191\n",
       "98  1.070411 -0.575302  0.138895\n",
       "99  0.708994 -1.038590  1.489848\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features using SelectFromModel class\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(estimator=model, max_features=3)\n",
    "X_transformed = sfm.fit_transform(X,y)\n",
    "support = sfm.get_support()\n",
    "data_regression.drop(columns=[\"target\"]).loc[:, support]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5513de9-1e71-4dcb-aa13-d77712bfbc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb94609-e248-4ee4-a236-8a4d2677fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef76e84-59fb-40f4-8b00-fb1032119a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
