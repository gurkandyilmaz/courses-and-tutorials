{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Attrition Prediction Using Node Embeddings\n#### Instead of using onehot, label or ordinal encoders, we will try to represent the data by node embeddings taken from a networkx graph.","metadata":{}},{"cell_type":"code","source":"!pip install node2vec","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:09.384649Z","iopub.execute_input":"2021-09-23T22:30:09.38514Z","iopub.status.idle":"2021-09-23T22:30:18.224951Z","shell.execute_reply.started":"2021-09-23T22:30:09.384972Z","shell.execute_reply":"2021-09-23T22:30:18.22387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nfrom typing import List, Dict, Set, Tuple\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn\n\nfrom pandas_profiling import ProfileReport\n\nattrition_data = '../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv'\ndf_attrition = pd.read_csv(attrition_data)\ndf_attrition","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:18.226669Z","iopub.execute_input":"2021-09-23T22:30:18.227705Z","iopub.status.idle":"2021-09-23T22:30:19.467774Z","shell.execute_reply.started":"2021-09-23T22:30:18.227661Z","shell.execute_reply":"2021-09-23T22:30:19.465269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprofile = ProfileReport(df_attrition, title='Attirition profiling')","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:21.586781Z","iopub.execute_input":"2021-09-23T22:30:21.587062Z","iopub.status.idle":"2021-09-23T22:30:21.598556Z","shell.execute_reply.started":"2021-09-23T22:30:21.587034Z","shell.execute_reply":"2021-09-23T22:30:21.597602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# profile.to_widgets()","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-23T22:30:21.790548Z","iopub.execute_input":"2021-09-23T22:30:21.7917Z","iopub.status.idle":"2021-09-23T22:30:21.795883Z","shell.execute_reply.started":"2021-09-23T22:30:21.791645Z","shell.execute_reply":"2021-09-23T22:30:21.79481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Alternative way of displaying profiling report","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-23T20:26:27.534217Z","iopub.execute_input":"2021-09-23T20:26:27.534784Z","iopub.status.idle":"2021-09-23T20:26:27.55148Z","shell.execute_reply.started":"2021-09-23T20:26:27.534738Z","shell.execute_reply":"2021-09-23T20:26:27.550473Z"}}},{"cell_type":"code","source":"# %%time\n# profile.to_notebook_iframe()","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-23T22:30:23.544828Z","iopub.execute_input":"2021-09-23T22:30:23.545176Z","iopub.status.idle":"2021-09-23T22:30:23.548867Z","shell.execute_reply.started":"2021-09-23T22:30:23.54514Z","shell.execute_reply":"2021-09-23T22:30:23.548142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From the pandas profiling report (Warnings Tab), there are highly correlated columns as well as all constant valued columns. I created a dictionary separating columns based on the warnings.","metadata":{}},{"cell_type":"code","source":"target_column = 'Attrition'\nselected_columns = ['EmployeeNumber', 'BusinessTravel', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime', 'Attrition']\n\ncolumns_grouped = {\n    'constant_columns' : ['EmployeeCount', 'Over18', 'StandardHours'],\n    'correlated_columns' : ['JobLevel', 'TotalWorkingYears', 'PerformanceRating', 'YearsWithCurrManager',    \n                            'YearsInCurrentRole', 'EducationField', 'StockOptionLevel', 'Department'],\n    'null_columns' : ['YearsSinceLastPromotion'],\n    'other_columns' : ['MonthlyRate', 'DailyRate', 'HourlyRate'],\n}\n\n# Remap certain column values to avoid name confusions for later use. \nnew_column_values = {\n    'OverTime':{'Yes':'yes_overtime', 'No':'no_overtime'}, \n    'BusinessTravel':{'Travel_Rarely':'Rarely', 'Travel_Frequently':'Frequently', 'Non-Travel':'NonTravel'}\n}\n\ndf_attrition = df_attrition.replace(new_column_values)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:25.817113Z","iopub.execute_input":"2021-09-23T22:30:25.817394Z","iopub.status.idle":"2021-09-23T22:30:25.827729Z","shell.execute_reply.started":"2021-09-23T22:30:25.817366Z","shell.execute_reply":"2021-09-23T22:30:25.827039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_attrition = df_attrition.loc[:, selected_columns]\ndf_attrition","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:45:23.807662Z","iopub.execute_input":"2021-09-23T22:45:23.808678Z","iopub.status.idle":"2021-09-23T22:45:23.827914Z","shell.execute_reply.started":"2021-09-23T22:45:23.808621Z","shell.execute_reply":"2021-09-23T22:45:23.826993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_attrition.loc[:, target_column]","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:29.481033Z","iopub.execute_input":"2021-09-23T22:30:29.481678Z","iopub.status.idle":"2021-09-23T22:30:29.491173Z","shell.execute_reply.started":"2021-09-23T22:30:29.481618Z","shell.execute_reply":"2021-09-23T22:30:29.490244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n\nonehot_encoder = OneHotEncoder( sparse = False, drop = 'if_binary', dtype = np.int32 )\nordinal_encoder = OrdinalEncoder()\nlabel_encoder = LabelEncoder() # for target encoding\n\ntarget_column_encoded = label_encoder.fit_transform(df_attrition[target_column])\n\nonehot_columns = ['Gender','JobRole', 'MaritalStatus', 'OverTime']\ncategorical_columns = ['Attrition', 'BusinessTravel']\n\nonehot_array = onehot_encoder.fit_transform( df_attrition.loc[:, onehot_columns] )\nonehot_encoded = pd.DataFrame(onehot_array, columns=onehot_encoder.get_feature_names( onehot_columns ))\n\nordinal_array = ordinal_encoder.fit_transform( df_attrition.loc[:, categorical_columns] )\nordinal_encoded = pd.DataFrame(ordinal_array, columns=categorical_columns)\n\ndf_attrition_encoded = pd.concat([onehot_encoded, ordinal_encoded], axis=1)\ndf_attrition_encoded = df_attrition_encoded.astype('int64')\ndf_attrition_encoded\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:29.587353Z","iopub.execute_input":"2021-09-23T22:30:29.588088Z","iopub.status.idle":"2021-09-23T22:30:29.659532Z","shell.execute_reply.started":"2021-09-23T22:30:29.588045Z","shell.execute_reply":"2021-09-23T22:30:29.658492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GRAPH BUILDER","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom typing import List\nfrom time import time\n\nclass GraphLoader:\n    def __init__(self):\n        self.graph = None\n        self.title = None\n        \n    def build_graph(self, \n                    dataframe: pd.DataFrame, \n                    columns: List, \n                    edge_list: List,\n                    verbose: bool = True,\n                    title: str = 'Unnamed'):\n        self.title = title\n        t0 = time()\n        self.graph = nx.Graph(name = self.title)\n\n        # Add Nodes to the graph.\n        for column in columns:\n            self.graph.add_nodes_from(dataframe[column].values, label=column)\n\n        # Add remaining columns as Node attributes. Optional\n        remaining = dataframe.columns.difference(columns)\n        for node, data in self.graph.nodes(data=True):\n            if data[\"label\"] == \"EmployeeNumber\":\n                self.graph.nodes[node][\"attributes\"] = dataframe.loc[dataframe[\"EmployeeNumber\"] == int(node), remaining].squeeze().to_dict()\n\n        # Add Edges.\n        for _, row in dataframe.loc[:, columns].iterrows():\n            for edge in edge_list:\n                self.graph.add_edge(row[edge[0]], row[edge[1]])\n        \n        if verbose:\n            print(f\"FINISHED in {np.round(time() - t0, 3)} seconds.\")\n            print(nx.info(self.graph))\n        \n        return self.graph\n\n    def draw_graph(self, graph: nx.Graph, node_colors: dict, node: str = None, radius: int = 1) -> None:\n        def assign_colors(graph: nx.Graph) -> List:\n            # Assign Colors to nodes\n            colors = []\n            for n, data in graph.nodes(data=True):\n                node = data[\"label\"]\n                colors.append(node_colors.get(node, \"black\"))\n            return colors\n\n        f = plt.figure(figsize = (20,12), facecolor=\"darkgray\")\n        ax = f.add_subplot()\n\n        if not node:    \n            plt.title(self.title)\n        else:\n            plt.title(f\"Ego Graph around the node {node}, (radius={radius})\")\n            graph = nx.ego_graph(graph, node, radius = radius)\n        \n        colors = assign_colors(graph)\n        nx.draw_networkx(graph, node_size = 800, node_color = colors, with_labels = True)\n        # Add an empty plot to set custom legends\n        from matplotlib.lines import Line2D\n        ax.scatter([],[])\n        legend_elements = [\n            Line2D([0], [0], marker='o', color='w', label='employee no', markerfacecolor = node_colors['EmployeeNumber'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='travel', markerfacecolor = node_colors['BusinessTravel'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='gender', markerfacecolor = node_colors['Gender'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='job role', markerfacecolor = node_colors['JobRole'], markersize=15),\n            Line2D([0], [0], marker='o', color='w', label='marital status', markerfacecolor = node_colors['MaritalStatus'], markersize=15),\n        ]\n        ax.legend(handles=legend_elements, loc='best')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:32.645226Z","iopub.execute_input":"2021-09-23T22:30:32.645509Z","iopub.status.idle":"2021-09-23T22:30:32.663658Z","shell.execute_reply.started":"2021-09-23T22:30:32.64548Z","shell.execute_reply":"2021-09-23T22:30:32.66274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nodes = selected_columns[:-1] \nedges = [(\"EmployeeNumber\",\"BusinessTravel\"),\n         (\"EmployeeNumber\",\"Gender\"),\n         (\"EmployeeNumber\",\"JobRole\"),\n         (\"EmployeeNumber\",\"MaritalStatus\"),\n         (\"EmployeeNumber\",\"OverTime\")]\n\nnode_colors = {\n    \"EmployeeNumber\": \"dodgerblue\", \n    \"BusinessTravel\":\"lightgreen\", \n    \"Gender\":\"tan\", \n    \"JobRole\":\"salmon\",\n    \"MaritalStatus\":\"darkcyan\",\n    \"OverTime\":\"peru\"\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:33.564969Z","iopub.execute_input":"2021-09-23T22:30:33.565465Z","iopub.status.idle":"2021-09-23T22:30:33.571303Z","shell.execute_reply.started":"2021-09-23T22:30:33.565411Z","shell.execute_reply":"2021-09-23T22:30:33.570667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph_loader = GraphLoader()\ndemo_graph = graph_loader.build_graph(\n            dataframe = df_attrition.loc[:5, selected_columns[:-1]],\n            columns = nodes, \n            edge_list = edges,\n            verbose = True,\n            title = 'Employe Attrition graph with only 5 samples of data'\n        )\n# graph_loader.draw_graph(demo_graph, node_colors, node = 5, radius = 2) # show only the nodes that are at a distance of 2 edges from the employee 5.\ngraph_loader.draw_graph(demo_graph, node_colors) # Show the whole graph","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:34.525921Z","iopub.execute_input":"2021-09-23T22:30:34.526401Z","iopub.status.idle":"2021-09-23T22:30:34.875237Z","shell.execute_reply.started":"2021-09-23T22:30:34.526358Z","shell.execute_reply":"2021-09-23T22:30:34.874652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"graph = graph_loader.build_graph(\n            dataframe = df_attrition.loc[:, selected_columns[:-1]],\n            columns = nodes, \n            edge_list = edges,\n            verbose = True,\n            title = 'Employe Attrition Graph'\n        )","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:37.545358Z","iopub.execute_input":"2021-09-23T22:30:37.54641Z","iopub.status.idle":"2021-09-23T22:30:38.810766Z","shell.execute_reply.started":"2021-09-23T22:30:37.546348Z","shell.execute_reply":"2021-09-23T22:30:38.809774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nimport networkx as nx\nimport pickle\nfrom node2vec import Node2Vec\nfrom pathlib import Path\n\nCWD = Path().cwd()\nEMBEDDINGS_DIR = CWD / 'embeddings'\nEMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\nSEED = 12\n\nclass VectorizerConfig:\n    dimensions = 64\n    walk_length = 30\n    num_walks = 50\n    window = 10\n    min_count = 1\n    batch_words = 4\n\nclass NodeEmbedding:\n\n    def __init__(self) -> None:\n        self.vectorizer = None\n        self.model = None\n        \n    def generate_random_walks(self, graph: nx.Graph, **params) -> None:\n        self.vectorizer = Node2Vec(graph, **params)\n        # return self.vectorizer\n\n    def fit(self, **params) -> gensim.models.Word2Vec:\n        if self.vectorizer is None:\n            raise Exception(\"No random walks. Generate Random walks by calling generate_random_walks() method first.\")\n        self.model = self.vectorizer.fit(**params)\n        \n        return self.model\n\n    def save_model(self, model: gensim.models.Word2Vec, save_to: Path = EMBEDDINGS_DIR, prefix: str = None) -> None:\n        d = VectorizerConfig.dimensions\n        w = VectorizerConfig.walk_length\n        n = VectorizerConfig.num_walks\n\n        embeddings_filename = f\"{prefix}_embeddings_{d}_{w}_{n}.txt\"\n        model_filename = f\"{prefix}_model_{d}_{w}_{n}.pkl\"\n        # Save only the embeddings in a txt file.\n        self.model.wv.save_word2vec_format(str(EMBEDDINGS_DIR/embeddings_filename))\n        # Save the entire model.\n        self.model.save(str(EMBEDDINGS_DIR/model_filename))\n        print(f\"Model and embeddings saved to: {str(EMBEDDINGS_DIR/model_filename)}\")\n\n    def load_model(self, model_filename: str = None, load_from: Path = EMBEDDINGS_DIR) -> gensim.models.Word2Vec:\n        if Path(EMBEDDINGS_DIR / model_filename).exists():\n            print(\"Loaded Model: \", model_filename)\n            with Path(EMBEDDINGS_DIR / model_filename).open(mode=\"r+b\") as file:\n                self.model = pickle.load(file)\n        else:\n            raise FileNotFoundError(f\"NOT found: {EMBEDDINGS_DIR / model_filename}\")\n        \n        return self.model\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:41.111261Z","iopub.execute_input":"2021-09-23T22:30:41.111553Z","iopub.status.idle":"2021-09-23T22:30:41.213854Z","shell.execute_reply.started":"2021-09-23T22:30:41.111524Z","shell.execute_reply":"2021-09-23T22:30:41.21303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\nembedder = NodeEmbedding()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:30:54.381491Z","iopub.execute_input":"2021-09-23T22:30:54.38207Z","iopub.status.idle":"2021-09-23T22:30:54.385672Z","shell.execute_reply.started":"2021-09-23T22:30:54.382026Z","shell.execute_reply":"2021-09-23T22:30:54.385126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedder.generate_random_walks(\n    graph,\n    dimensions = VectorizerConfig.dimensions,\n    walk_length = VectorizerConfig.walk_length,\n    num_walks = VectorizerConfig.num_walks,\n    workers = multiprocessing.cpu_count()\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:21:36.742002Z","iopub.execute_input":"2021-09-23T22:21:36.742416Z","iopub.status.idle":"2021-09-23T22:23:12.674067Z","shell.execute_reply.started":"2021-09-23T22:21:36.742387Z","shell.execute_reply":"2021-09-23T22:23:12.673274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel = embedder.fit(\n    window = VectorizerConfig.window,\n    min_count = VectorizerConfig.min_count,\n    batch_words = VectorizerConfig.batch_words\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:23:12.677467Z","iopub.execute_input":"2021-09-23T22:23:12.677828Z","iopub.status.idle":"2021-09-23T22:24:46.789431Z","shell.execute_reply.started":"2021-09-23T22:23:12.677779Z","shell.execute_reply":"2021-09-23T22:24:46.788563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedder.save_model(model, save_to = EMBEDDINGS_DIR, prefix = \"attrition\")","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:24:46.790786Z","iopub.execute_input":"2021-09-23T22:24:46.791094Z","iopub.status.idle":"2021-09-23T22:24:46.87357Z","shell.execute_reply.started":"2021-09-23T22:24:46.791042Z","shell.execute_reply":"2021-09-23T22:24:46.872825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = embedder.load_model(\"attrition_model_64_30_50.pkl\", load_from = EMBEDDINGS_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:31:04.620593Z","iopub.execute_input":"2021-09-23T22:31:04.620914Z","iopub.status.idle":"2021-09-23T22:31:04.628514Z","shell.execute_reply.started":"2021-09-23T22:31:04.620883Z","shell.execute_reply":"2021-09-23T22:31:04.627441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(EMBEDDINGS_DIR / 'attrition_embeddings_64_30_50.txt', 'r') as embeddings_file:\n    embeddings = embeddings_file.readlines()","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:33:49.890116Z","iopub.execute_input":"2021-09-23T22:33:49.890447Z","iopub.status.idle":"2021-09-23T22:33:49.897637Z","shell.execute_reply.started":"2021-09-23T22:33:49.890416Z","shell.execute_reply":"2021-09-23T22:33:49.896616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first element in the embeddings txt are the node counts and the embedding dimension, respectively.\nembeddings[:5]","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:33:51.214453Z","iopub.execute_input":"2021-09-23T22:33:51.215055Z","iopub.status.idle":"2021-09-23T22:33:51.220287Z","shell.execute_reply.started":"2021-09-23T22:33:51.215012Z","shell.execute_reply":"2021-09-23T22:33:51.219619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def align_features_and_target(df: pd.DataFrame, embeddings_file: str = None):\n    vectors = []\n    with Path(EMBEDDINGS_DIR / embeddings_file).open(mode=\"r\") as file:\n        results = file.readlines()\n        for person in df[\"EmployeeNumber\"].values:\n            for line in results[1:]:\n                if line.split()[0] == str(person):\n                    vectors.append(line.split()[1:])\n    \n    return np.array(vectors).astype(np.float64)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:43:17.624502Z","iopub.execute_input":"2021-09-23T22:43:17.625312Z","iopub.status.idle":"2021-09-23T22:43:17.630885Z","shell.execute_reply.started":"2021-09-23T22:43:17.625262Z","shell.execute_reply":"2021-09-23T22:43:17.630238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nembeddings_filename = \"attrition_embeddings_64_30_50.txt\"\nvectors2 = align_features_and_target(df_attrition, embeddings_file = embeddings_filename)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:43:19.838498Z","iopub.execute_input":"2021-09-23T22:43:19.839541Z","iopub.status.idle":"2021-09-23T22:43:29.342655Z","shell.execute_reply.started":"2021-09-23T22:43:19.839496Z","shell.execute_reply":"2021-09-23T22:43:29.341924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors2.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:47:25.387144Z","iopub.execute_input":"2021-09-23T22:47:25.387587Z","iopub.status.idle":"2021-09-23T22:47:25.393748Z","shell.execute_reply.started":"2021-09-23T22:47:25.387557Z","shell.execute_reply":"2021-09-23T22:47:25.393125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# node_targets = np.array(list(map(lambda label: 1 if label == \"Yes\" else 0, df_attrition[\"Attrition\"])))\nnode_targets = df_attrition_encoded['Attrition'].values\nnode_targets.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T22:47:54.388758Z","iopub.execute_input":"2021-09-23T22:47:54.389185Z","iopub.status.idle":"2021-09-23T22:47:54.395591Z","shell.execute_reply.started":"2021-09-23T22:47:54.389155Z","shell.execute_reply":"2021-09-23T22:47:54.394759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import cross_validate, GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve, r2_score\n\nprint(f'Original target value counts: {Counter(node_targets)}')\nprint(f'Train vectors shape: ', vectors2.shape)\n\n### OVER SAMPLING ###\nprint('\\n<--------------OVERSAMPLING---------------->\\n')\n# over_sampler = SMOTE(sampling_strategy = 1.0, k_neighbors = 5, random_state = 12)\n# features, target = over_sampler.fit_resample(vectors2, node_targets)\nx_train, x_test, y_train, y_test = train_test_split(\n    vectors2, \n    node_targets, \n    test_size = 0.25, \n    random_state = 12, \n    stratify = node_targets\n)\n\nprint(f'After oversampling target counts: {Counter(target)}')\nprint(f'feature train shape After oversampling: ', features.shape)\n\nclassifiers = {\n        'LogisticReg': LogisticRegression(), \n        'SVC': SVC(), \n        'SGD': SGDClassifier(), \n        'GBC': GradientBoostingClassifier(),\n        'kNN': KNeighborsClassifier()\n}\n\nscores = dict()\nfor name, classifier in classifiers.items():\n        print(f'\\n<------------- MODEL: {name} ----------->')\n#         scores[name] = cross_validate(classifier, x_train, y_train, cv = 10, scoring = 'f1', return_train_score = False)\n        classifier.fit(x_train, y_train)\n        print(classification_report(y_test, classifier.predict(x_test), zero_division = 0))\n        print(f'<------------- END ----------->\\n')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:18:53.338444Z","iopub.execute_input":"2021-09-23T23:18:53.33917Z","iopub.status.idle":"2021-09-23T23:18:55.8867Z","shell.execute_reply.started":"2021-09-23T23:18:53.339119Z","shell.execute_reply":"2021-09-23T23:18:55.885703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(309*0.91 + 59*0.21) / (309+59)","metadata":{"execution":{"iopub.status.busy":"2021-09-23T23:22:21.767328Z","iopub.execute_input":"2021-09-23T23:22:21.767706Z","iopub.status.idle":"2021-09-23T23:22:21.773915Z","shell.execute_reply.started":"2021-09-23T23:22:21.767668Z","shell.execute_reply":"2021-09-23T23:22:21.773268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntarget = df_attrition_encoded['Attrition'].values\nfeatures = df_attrition_encoded.drop(columns=['Attrition'])\n\nX_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size = 0.25, random_state = 12, stratify = target)\n\nclassifiers = {\n        'LogisticReg': LogisticRegression(), \n        'SVC': SVC(), \n        'SGD': SGDClassifier(), \n        'GBC': GradientBoostingClassifier(),\n        'kNN': KNeighborsClassifier()\n}\n\nfor name, classifier in classifiers.items():\n        print(f'<------------- MODEL: {name} ----------->')\n        classifier.fit(X_train, Y_train)\n        print(classification_report(Y_test, classifier.predict(X_test), zero_division = 0))\n        print(f'<------------- END ----------->\\n')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2021-09-23T23:17:21.019414Z","iopub.execute_input":"2021-09-23T23:17:21.019726Z","iopub.status.idle":"2021-09-23T23:17:21.308243Z","shell.execute_reply.started":"2021-09-23T23:17:21.019693Z","shell.execute_reply":"2021-09-23T23:17:21.307261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Edge Embedding\nfrom node2vec.edges import HadamardEmbedder\nedges_embs = HadamardEmbedder(keyed_vectors=model.wv)\nedges_embs[('1', '2')]\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edges_kv = edges_embs.as_keyed_vectors()\nedges_kv.most_similar(str(('1', '2')))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dimensionality reduction\nfrom sklearn.manifold import TSNE\nfrom matplotlib import patches\nimport seaborn\n\nseaborn.set_style('whitegrid')\n\n# for node, data in G_karate.nodes(data=True):\n#     print(node, data)\nembeddings = np.array([model.wv[node] for node in graph.nodes])\ntsne = TSNE(n_components=2, random_state=7, perplexity=15)\nembeddings_2d = tsne.fit_transform(embeddings)\nfigure = plt.figure(figsize=(11, 9))\n\nax = figure.add_subplot(111)\n\nax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n\n# Create team patches for legend\n# team_patches = [mpatches.Patch(color=color, label=team) for team, color in team_colors.items()]\n# ax.legend(handles=team_patches);\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Pathlib Tutorial\nfrom pathlib import Path, PurePath, PosixPath, PurePosixPath, PureWindowsPath\np = Path('../data')\n\nfor file in p.iterdir():\n    print(file)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Exists: ', p.exists())\nprint('is dir: ', p.is_dir())\nprint('is file: ', p.is_file())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(p.glob('**/*.csv'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('CWD: ', Path.cwd())\nprint('Home: ', Path.home())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_something(**kwargs):\r\n    print(type(kwargs))\r\n    print(kwargs)\r\n\r\ntest = {\r'  ' \"x'\": ['te't\", 'ke't\", 'mest\"],'\n    \"'ar'et\":'\"haha\"'\r\n'  '\"'2\"'['t\", \"h\"]\r\n}\r\ntest_something(a=15, b=21, c=100, d=15)","metadata":{},"execution_count":null,"outputs":[]}]}